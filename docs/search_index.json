[["index.html", "Stochastic Calculus: An Idiosyncratic Approach Preface What You’ll Learn Prerequisites About This Book Book Overview", " Stochastic Calculus: An Idiosyncratic Approach Abhinav Anand 2026-01-11 Preface Welcome to Stochastic Calculus: An Idiosyncratic Approach! This book provides a discussion regarding special features of the mathematics behind random processes like the Brownian Motion and their applications in finance. What You’ll Learn This book covers: Random walks and Brownian motion Itô’s lemma and stochastic integration Stochastic differential equations (SDEs) The Feynman-Kac connection between SDEs and PDEs Risk-neutral pricing and martingales Black-Scholes theory and the Greeks Jump-diffusion models Lévy processes Prerequisites Readers should be comfortable with: Calculus (derivatives, integrals) Basic probability theory (random variables, expectations, variance) Linear algebra fundamentals About This Book This book grew out of years of instruction at the PhD and MBA levels in IIMs Bangalore and Kozhikode. It reflects my idiosyncratic perspective on topics in mathematical finance and its pedagogy. The emphasis is on understanding why things work, not what the formulas are. Each chapter builds on previous concepts, so I recommend reading sequentially, especially if you’re new to the subject. Book Overview This book is organized into eight chapters that build progressively from foundational concepts to advanced generalizations. Part I: Foundations Random Walks and Brownian Motion From discrete coin flips to continuous paths—establishing why \\((dB)^2 = dt\\) We begin with the simple random walk and watch it transform into Brownian motion through careful scaling. The central revelation: stochastic infinitesimals behave differently from classical ones, setting the stage for everything that follows. Itô Integral and Itô’s Lemma The fundamental theorem for stochastic processes Classical integration fails for Brownian paths. We construct the Itô integral and derive Itô’s lemma—the chain rule of stochastic calculus, complete with its surprising correction term. Stochastic Differential Equations Geometric Brownian Motion, Ornstein-Uhlenbeck, and solution techniques The workhorse models of mathematical finance. We solve key SDEs and develop intuition for when closed-form solutions exist. Part II: The PDE Connection Feynman-Kac and PDEs The bridge between probability and partial differential equations A remarkable duality: expectations over random paths solve deterministic PDEs. This connection underlies both theoretical insights and computational methods. Part III: Mathematical Finance Risk-Neutral Pricing and Martingales No-arbitrage, Girsanov’s theorem, and the fundamental theorem of asset pricing The conceptual foundation of derivative pricing. We explore why “fair games” (martingales) are central to finance and how changing probability measures eliminates arbitrage. Black-Scholes Theory Option pricing, the Greeks, and delta hedging The celebrated formula and its practical toolkit. We derive the Greeks, understand hedging, and confront the model’s limitations through implied volatility. Part IV: Beyond Diffusions Jump-Diffusion Models When continuous paths aren’t enough—Merton’s model and the PIDE Markets jump. We extend our framework to incorporate discontinuous price movements, leading to partial integro-differential equations. Lévy Processes The ultimate generalization: infinite divisibility and the Lévy-Khintchine formula The grand unification. Every process with independent, stationary increments—from Brownian motion to pure jump processes—falls under this umbrella. "],["random-walks-and-brownian-motion.html", "Chapter 1 Random Walks and Brownian Motion 1.1 Why Random Walks Matter 1.2 Simple Random Walk 1.3 From Discrete Steps to Continuous Paths 1.4 Brownian Motion: The Continuous Limit 1.5 A Crisis and An Opportunity: Rethinking Calculus", " Chapter 1 Random Walks and Brownian Motion In 1827, botanist Robert Brown observed pollen grains suspended in water through his microscope, jittering ceaselessly in an erratic dance. Nearly eighty years later, Einstein explained this Brownian motion: each grain is bombarded by countless invisible water molecules, accumulating random kicks that send it on a wandering path—a continuous random walk. Yet here’s the puzzle that should make you pause: in 1900, five years before Einstein’s physics paper, a French mathematician named Louis Bachelier wrote his doctoral thesis describing stock price movements using the exact same mathematical framework. How could the physics of microscopic particles and the economics of human market behavior—phenomena separated by scales of size, time, and causation—obey identical mathematical laws? The answer hints at a deep universality: whenever a quantity evolves through the accumulation of many small, independent, unpredictable shocks—whether molecular collisions or market trades—the Central Limit Theorem sculpts the result into the same characteristic shape, regardless of the underlying details. 1.1 Why Random Walks Matter Imagine a particle suspended in fluid, buffeted by molecular collisions. Or the path of a stock price over time, influenced by countless buy and sell decisions. Or even the position of a gambler’s fortune after many coin flips. What unifies these seemingly disparate phenomena? They all exhibit random walk behavior. Random walks are fundamental models in probability theory with applications spanning physics (diffusion processes), finance (asset price modeling), biology (animal foraging), and computer science (randomized algorithms). Understanding random walks gives us the key to analyzing systems where change occurs through accumulated random shocks. This chapter’s journey: We’ll begin with the simplest random walk—a sequence of coin flips—and discover that when properly scaled, these discrete jumps converge to a continuous process called Brownian motion. This limiting process is not just mathematically elegant; it’s the foundation of stochastic calculus and modern quantitative finance. Three questions will guide us: 1. How does a random walk behave over time? 2. What happens when we standardize it? 3. How do we transition from discrete steps to continuous motion? 1.2 Simple Random Walk Imagine flipping a fair coin repeatedly. After each flip, you take a step: heads = +1, tails = -1. Your position after \\(n\\) steps is: \\[S_n = X_1 + X_2 + \\cdots + X_n\\] where each \\(X_i \\in \\{-1, +1\\}\\) with equal probability \\(1/2\\). This is a simple random walk. Intuition: Think of \\(S_n\\) as your “signed distance” from where you started. Each coin flip adds a random \\(\\pm 1\\) to your position. Since the coin is fair, there’s no systematic drift in any direction—but randomness ensures you won’t stay at zero either. 1.2.1 Key Properties Now that we’ve defined the random walk, let’s examine what makes it tick. Three properties will be crucial for understanding its long-term behavior: Expected position: \\(\\mathbb{E}[S_n] = 0\\) Interpretation: On average, you expect to end where you started. The walk has no drift or bias. Variance: \\(\\text{Var}(S_n) = n\\) Interpretation: The variance grows linearly with time. The typical distance from the origin grows, but crucially, it grows as \\(\\sqrt{n}\\), not as \\(n\\) itself. Asymptotic normality: \\(\\frac{S_n}{\\sqrt{n}} \\xrightarrow{d} N(0,1)\\) as \\(n \\to \\infty\\) Interpretation: By the Central Limit Theorem, even though each step is discrete (\\(\\pm 1\\)), the rescaled position becomes approximately normal for large \\(n\\). Here \\(\\xrightarrow{d}\\) denotes convergence in distribution. Why these properties matter: The first two tell us about the walk’s center and spread. The third—asymptotic normality—is profound: it means that regardless of the distribution of individual steps, their sum (properly scaled) becomes Gaussian. This universality is what makes random walks so powerful as models.  Thought Exercise: Why does variance grow linearly with \\(n\\) but standard deviation grow as \\(\\sqrt{n}\\)? What does this imply about how “surprising” a deviation of size \\(k\\) becomes as time progresses? Hint: Since \\(\\text{SD}(S_n) = \\sqrt{n}\\), a deviation of fixed size \\(k\\) represents \\(k/\\sqrt{n}\\) standard deviations. As \\(n\\) increases, the same absolute deviation becomes less and less surprising in relative terms. 1.2.2 Visualizing Random Walk Behavior Theory is one thing, but seeing is believing. The following simulations will demonstrate each property we just discussed. As you examine each plot, ask yourself: - Does the behavior match our mathematical predictions? - What patterns emerge as time increases? - Can you visually identify the \\(\\sqrt{n}\\) scaling in the spread? (#fig:rw_simulate)Five independent random walk paths over 1000 steps. Each colored line represents one realization of the random walk process. What we observe: Each path wanders unpredictably—sometimes venturing far from zero, other times hovering nearby. Yet they all cluster around zero on average. This is \\(\\mathbb{E}[S_n] = 0\\) in action. Notice how the spread of paths increases over time—that’s the \\(\\text{Var}(S_n) = n\\) property manifesting visually. By \\(n = 1000\\), paths range roughly from \\(-60\\) to \\(+60\\), which aligns with our prediction: we expect typical deviations of about \\(\\pm 2\\sqrt{1000} \\approx \\pm 63\\) (two standard deviations). (#fig:rw_sqrt)Random walk volatility envelope. The dashed lines show \\(\\pm 1\\) standard deviation bounds, which grow as \\(\\sqrt{n}\\). Theory predicts: The standard deviation envelope should grow as \\(\\sqrt{n}\\). At \\(n = 100\\), we expect \\(\\text{SD} \\approx 10\\). At \\(n = 400\\), we expect \\(\\text{SD} \\approx 20\\) (doubling the time quadruples the variance but only doubles the standard deviation). At \\(n = 1000\\), we expect \\(\\text{SD} \\approx 31.6\\). What the plot confirms: The \\(\\pm 1\\sigma\\) envelope (dashed lines) indeed follows the \\(\\sqrt{n}\\) curve. The sample path wanders within and occasionally beyond this envelope, exactly as we’d expect from a process whose deviations follow a normal distribution (recall that roughly 68% of a normal distribution lies within \\(\\pm 1\\sigma\\)). Empirical verification: Simulating many random walks allows us to check whether sample means and variances match theoretical predictions. (#fig:rw_mean)Empirical mean of 10,000 random walk simulations at each time point. The mean hovers near zero, confirming \\(\\mathbb{E}[S_n] = 0\\). What we see: The empirical mean (blue line) fluctuates slightly around zero due to Monte Carlo noise, but remains remarkably close to the theoretical value. This is the Law of Large Numbers at work: averaging over 10,000 independent walks gives us an accurate estimate of the true expectation. (#fig:rw_variance)Empirical variance of 10,000 random walk simulations. The variance grows linearly with time, confirming \\(\\text{Var}(S_n) = n\\). Quantitative check: At \\(n = 500\\), we predict \\(\\text{Var}(S_n) = 500\\). The empirical variance tracks the 45-degree line (where variance equals time) almost perfectly. Any small deviations are due to finite-sample variation—with 10,000 simulations, our estimates are quite precise. 1.2.3 The Central Limit Theorem in Action Now for the most important property: asymptotic normality. If we standardize the random walk by subtracting its mean (which is 0) and dividing by its standard deviation (which is \\(\\sqrt{n}\\)), the resulting distribution should approach the standard normal: \\[Z_n := \\frac{S_n - 0}{\\sqrt{n}} = \\frac{S_n}{\\sqrt{n}} \\xrightarrow{d} N(0,1)\\] Why this rescaling? Dividing by \\(\\sqrt{n}\\) (not \\(n\\)) is crucial. If we divided by \\(n\\), the random walk would vanish: \\(S_n/n \\to 0\\). If we didn’t divide at all, \\(S_n\\) would diverge. The \\(\\sqrt{n}\\) factor is the “Goldilocks” scaling that keeps the variance at exactly 1 and allows convergence to a non-degenerate limit. (#fig:rw_clt)Histograms of standardized random walks at various time points. As \\(n\\) increases, the empirical distribution (blue bars) converges to the standard normal density (red curve). Visual convergence: At \\(n = 10\\), the histogram is somewhat jagged and discrete-looking. By \\(n = 100\\), it’s smoother and closer to the normal curve. At \\(n = 1000\\), the fit is nearly perfect. This is the Central Limit Theorem before your eyes: sums of independent random variables, when properly normalized, converge to the normal distribution. Figure 1.1: Quantile-quantile (Q-Q) plot comparing empirical quantiles of \\(S_n/\\sqrt{n}\\) to theoretical quantiles of \\(N(0,1)\\). Points falling on the diagonal indicate distributional agreement. The Q-Q plot diagnostic: This plot compares quantiles directly. If the standardized random walk were exactly normal, all points would fall on the diagonal line. We see excellent agreement, especially in the central range (\\(-2\\) to \\(+2\\)). Some deviation in the extreme tails is normal—after all, we’re working with finite samples and approximations. 1.2.4 Synthesis: What We’ve Learned Let’s review the visual and mathematical evidence: Zero drift: Random walks with symmetric steps (equal probability of \\(\\pm 1\\)) have expected value zero at all times. Linear variance growth: The variance grows as \\(n\\), which means standard deviation grows as \\(\\sqrt{n}\\). The “uncertainty region” widens, but sub-linearly. Convergence to normality: The standardized random walk’s empirical distribution converges to the standard normal density. Mathematically: \\[\\begin{align} \\frac{S_n - 0}{\\sqrt{n}} &amp;\\xrightarrow{d} N(0,1)\\\\ \\Rightarrow \\quad S_n &amp;\\xrightarrow{d} \\sqrt{n} \\cdot N(0,1) \\end{align}\\] Practical implication: For large \\(n\\), we can approximate probabilities for \\(S_n\\) using the normal distribution. For example: \\[P(S_n \\leq x) \\approx \\Phi\\left(\\frac{x}{\\sqrt{n}}\\right)\\] where \\(\\Phi\\) is the standard normal cumulative distribution function. 1.2.5 Common Pitfalls and Misconceptions Before moving forward, let’s address some common sources of confusion: ❌ Misconception: “The random walk will eventually return to zero.” ✓ Reality: While it’s true that \\(\\mathbb{E}[S_n] = 0\\) for all \\(n\\), this doesn’t mean \\(S_n\\) itself will be zero at any particular time. In fact, for a simple random walk, the probability of ever returning to zero is 1 (a beautiful result!), but there’s no guarantee it happens within any finite time window. ❌ Misconception: “I should standardize by dividing by \\(n\\).” ✓ Reality: Dividing \\(S_n\\) by \\(n\\) gives \\(S_n/n \\to 0\\) (by the Law of Large Numbers), which is trivial. The correct scaling is \\(S_n/\\sqrt{n}\\), which preserves variance and yields a meaningful limit. ❌ Misconception: “The next step depends on previous steps.” ✓ Reality: The random walk is memoryless—each \\(X_i\\) is independent. While \\(S_n\\) certainly depends on past steps (it’s their sum!), the increment \\(X_{n+1}\\) does not. This independence is crucial for many theoretical results. ❌ Misconception: “Since the walk is symmetric, it spends equal time above and below zero.” ✓ Reality: This is false for finite \\(n\\)! The walk can exhibit long excursions on one side. However, the arcsine law tells us that over long times, the proportion of time spent positive converges to a surprisingly non-uniform distribution. 1.2.6 From Discrete to Continuous: Brownian Motion Preview We’ve seen that random walks, when properly scaled, converge to normal distributions at each fixed time \\(n\\). But what if we wanted a continuous-time process? Here’s the key insight: imagine taking steps more and more frequently, but making each step proportionally smaller. Specifically: Divide the time interval \\([0, t]\\) into \\(n\\) subintervals of length \\(\\Delta t = t/n\\) At each subinterval, take a step of size \\(\\pm \\sqrt{\\Delta t}\\) (not \\(\\pm 1\\)!) Let \\(n \\to \\infty\\) This limiting process—called Donsker’s invariance principle—yields Brownian motion \\(B(t)\\), a continuous-time stochastic process with remarkable properties: \\(B(0) = 0\\) (starts at the origin) Independent increments: \\(B(t) - B(s)\\) is independent of the past for \\(t &gt; s\\) Stationary increments: \\(B(t) - B(s) \\sim N(0, t-s)\\) (depends only on time difference) Continuous paths: \\(B(t)\\) is continuous in \\(t\\) (though nowhere differentiable!) Visual intuition: If you plotted random walks with \\(n = 10, 100, 1000, 10000\\) steps (each step scaled by \\(1/\\sqrt{n}\\)), you’d see the paths become increasingly continuous. The limit is Brownian motion—a continuous but highly irregular function. Why this matters: Brownian motion is the continuous analog of the random walk and serves as the foundation for: - Stochastic calculus: Integration and differentiation with respect to random processes - Financial modeling: The Black-Scholes model assumes stock prices follow geometric Brownian motion - Partial differential equations: Solutions to the heat equation can be represented as expectations over Brownian paths In the next sections, we’ll formally define Brownian motion, explore its properties, and begin developing the calculus of random functions. 1.3 From Discrete Steps to Continuous Paths We’ve thoroughly explored the simple random walk—a process that jumps at discrete integer times \\(n = 1, 2, 3, \\ldots\\). But many real phenomena unfold continuously: pollen grains don’t wait for a clock to tick before changing direction, and stock prices can move at any instant during trading hours. How do we bridge this gap? The key insight: we’ll take our discrete random walk and refine it twice—making steps more frequent and smaller—in just the right proportion so that something meaningful survives in the limit. 1.3.1 The Scaling Thought Experiment Imagine we want to model a process over time interval \\([0, t]\\). We’ll compare three different strategies: Strategy 1 (Naive): Divide \\([0, t]\\) into \\(n\\) subintervals of length \\(\\Delta t = t/n\\). At each subinterval, take a step of size \\(\\pm 1\\). - Position after \\(n\\) steps: \\(S_n \\approx \\sqrt{n} \\sim \\sqrt{t/\\Delta t}\\) - As \\(\\Delta t \\to 0\\): \\(S_n \\to \\infty\\) (diverges!) Strategy 2 (Over-correction): Use step size \\(\\pm \\Delta t\\) instead. - Position: \\(S_n \\approx \\sqrt{n} \\cdot \\Delta t \\sim \\sqrt{n/t^2} \\to 0\\) (vanishes!) Strategy 3 (Goldilocks): Use step size \\(\\pm \\sqrt{\\Delta t}\\). - Position variance: \\(n \\cdot (\\sqrt{\\Delta t})^2 = n \\cdot \\Delta t = (t/\\Delta t) \\cdot \\Delta t = t\\) ✓ - As \\(\\Delta t \\to 0\\): we get a non-trivial limit! The third strategy is the magic formula. Let’s see why it works mathematically. 1.3.2 The Crucial Scaling Derivation Suppose we divide the time interval \\([0, t]\\) into \\(n\\) subintervals of length \\(\\Delta t = t/n\\). At each time step, we take a random step of size \\(\\Delta x\\). After \\(n\\) steps, our position is: \\[S_n = \\sum_{i=1}^{n} X_i\\] where each \\(X_i \\in \\{-\\Delta x, +\\Delta x\\}\\) with equal probability. We already know: - \\(\\mathbb{E}[S_n] = 0\\) (regardless of \\(\\Delta x\\)) - \\(\\text{Var}(S_n) = n \\cdot (\\Delta x)^2\\) What should the variance be? If we want the limiting process to have variance proportional to elapsed time \\(t\\) (as we’ve seen with random walks where \\(\\text{Var}(S_n) = n\\)), we need: \\[\\text{Var}(S_n) = n \\cdot (\\Delta x)^2 = t\\] Substituting \\(n = t/\\Delta t\\): \\[\\frac{t}{\\Delta t} \\cdot (\\Delta x)^2 = t\\] Solving for \\(\\Delta x\\): \\[(\\Delta x)^2 = \\Delta t \\quad \\Rightarrow \\quad \\boxed{\\Delta x = \\sqrt{\\Delta t}}\\] The profound implication: As we make time steps smaller by a factor of \\(k\\) (i.e., \\(\\Delta t \\to \\Delta t/k\\)), we must make spatial steps smaller by a factor of \\(\\sqrt{k}\\) (i.e., \\(\\Delta x \\to \\Delta x/\\sqrt{k}\\)). Steps shrink, but only like the square root of the time resolution.  Intuition Check: Why square root scaling? Think back to our random walk property: \\(\\text{SD}(S_n) = \\sqrt{n}\\). When we compress \\(n\\) steps into a fixed time interval \\(t\\), we need each step’s contribution to scale as \\(1/\\sqrt{n}\\) so that the total variance remains finite. 1.3.3 Visualizing the Convergence Let’s see this convergence in action by simulating random walks with increasingly fine time discretizations: What we observe: - With \\(n = 10\\) steps (left panel): The path is clearly discrete, with visible jumps. - With \\(n = 100\\) steps (middle panel): The path appears smoother but still jagged. - With \\(n = 10{,}000\\) steps (right panel): The path looks nearly continuous—this is Brownian motion emerging. Each panel represents the same time interval \\([0, 1]\\), but with different levels of discretization. As \\(n \\to \\infty\\) (and \\(\\Delta t \\to 0\\)), these paths converge to a limiting continuous process. 1.4 Brownian Motion: The Continuous Limit 1.4.1 Formal Definition Taking the limit as \\(\\Delta t \\to 0\\) in our scaled random walk, we obtain a continuous stochastic process \\(\\{B(t) : t \\geq 0\\}\\) called standard Brownian motion (or the Wiener process) if it satisfies: Starts at the origin: \\(B(0) = 0\\) Independent increments: For any times \\(0 \\leq t_1 &lt; t_2 &lt; t_3 &lt; t_4\\), the increments \\(B(t_2) - B(t_1)\\) and \\(B(t_4) - B(t_3)\\) are independent. Interpretation: The process has no memory—what happens in disjoint time intervals is statistically independent. Stationary normal increments: For any \\(0 \\leq s &lt; t\\), \\[B(t) - B(s) \\sim N(0, t-s)\\] Interpretation: Over any time interval of length \\(\\tau = t - s\\), the displacement is normally distributed with mean zero and variance \\(\\tau\\). The distribution depends only on the length of the interval, not its position. Continuous paths: \\(t \\mapsto B(t)\\) is a continuous function with probability 1. Interpretation: Unlike the random walk, which jumps, Brownian motion flows continuously. You can draw its path without lifting your pen (though it would be infinitely wiggly!). 1.4.2 Understanding the Properties Let’s unpack these conditions with concrete examples: Property 1 (Origin): This is a normalization. If we wanted \\(B(t)\\) to start elsewhere, we’d simply add a constant: \\(B(t) + x_0\\). Property 2 (Independence): Suppose you observe \\(B(t) = 5\\) at time \\(t = 1\\). What does this tell you about \\(B(2) - B(1)\\)? Nothing! The increment is still \\(N(0, 1)\\), independent of where the process currently sits. This memoryless property is inherited from the random walk. Property 3 (Stationarity): The distribution of \\(B(t) - B(s)\\) depends only on \\(t - s\\). So \\(B(2) - B(1)\\) has the same distribution as \\(B(102) - B(101)\\)—both are \\(N(0, 1)\\). But \\(B(3) - B(1) \\sim N(0, 2)\\) has larger variance because it spans a longer time interval. Property 4 (Continuity): This seems innocent but leads to shocking consequences, as we’ll see next.  Connection to Random Walk: Notice that if we evaluate Brownian motion at discrete times \\(t = k \\cdot \\Delta t\\) for \\(k = 0, 1, 2, \\ldots\\), the increments \\(B(k\\Delta t) - B((k-1)\\Delta t)\\) are i.i.d. \\(N(0, \\Delta t)\\). This is exactly a scaled random walk! Brownian motion is the continuous interpolation between these points. 1.4.3 An Important Consequence: Quadratic Variation From Property 3, we can immediately derive a key fact: \\[\\mathbb{E}[B(t)] = 0 \\quad \\text{and} \\quad \\text{Var}(B(t)) = t\\] So \\(B(t) \\sim N(0, t)\\), meaning: \\[B(t) \\overset{d}{=} \\sqrt{t} \\cdot Z\\] where \\(Z \\sim N(0, 1)\\). Physical interpretation: A particle undergoing Brownian motion has typical displacement \\(\\sim \\sqrt{t}\\) after time \\(t\\). Its position grows sub-linearly—if you wait four times as long, you only expect to be twice as far from the origin (in terms of standard deviation). Financial interpretation (Bachelier, 1900): If stock price movements follow Brownian motion, the uncertainty in price grows as \\(\\sqrt{t}\\). This means volatility (uncertainty per unit time) scales as \\(1/\\sqrt{t}\\)—longer time horizons provide more predictability per unit time. 1.4.4 The Shocking Fact: Nowhere Differentiable Here’s the counterintuitive reality: Brownian motion is continuous everywhere but differentiable nowhere (with probability 1). It’s infinitely jagged at every time scale! Why this happens: Differentiability means: \\[\\lim_{\\Delta t \\to 0} \\frac{B(t + \\Delta t) - B(t)}{\\Delta t} \\text{ exists}\\] But we know \\(B(t + \\Delta t) - B(t) \\sim N(0, \\Delta t)\\), which means: \\[\\frac{B(t + \\Delta t) - B(t)}{\\Delta t} \\sim N\\left(0, \\frac{1}{\\Delta t}\\right)\\] As \\(\\Delta t \\to 0\\), the variance of this ratio diverges! The “derivative” has infinite variance—it doesn’t exist in the classical sense. (#fig:nowhere_diff)Zooming into a Brownian path. Each successive zoom (left to right) reveals the same rough, jagged structure—there are no smooth segments, no matter how close you look. What the figure shows: Three panels showing the same Brownian path at increasing magnifications around \\(t = 0.5\\). Notice that the path never smooths out—the jaggedness is self-similar at all scales. This is fundamentally different from smooth functions like \\(\\sin(t)\\) or \\(t^2\\), which look linear when you zoom in enough. Practical implication: You cannot use calculus in the usual sense. The expression \\(dB(t)/dt\\) is meaningless. This is why we need stochastic calculus—a new calculus built specifically for these nowhere-differentiable paths. 1.5 A Crisis and An Opportunity: Rethinking Calculus The nowhere-differentiability of Brownian motion isn’t just a mathematical curiosity—it represents a fundamental crisis for classical calculus and simultaneously opens the door to something new. 1.5.1 Why Classical Calculus Fails Classical calculus rests on a foundation of slopes. The derivative: \\[f&#39;(t) = \\lim_{\\Delta t \\to 0} \\frac{f(t + \\Delta t) - f(t)}{\\Delta t}\\] measures the instantaneous rate of change. From this single concept flows everything: tangent lines, optimization, differential equations, and integration (via the fundamental theorem). But for Brownian motion, this foundation crumbles. We’ve seen that: \\[\\frac{B(t + \\Delta t) - B(t)}{\\Delta t} \\sim N\\left(0, \\frac{1}{\\Delta t}\\right)\\] As \\(\\Delta t \\to 0\\), this ratio doesn’t converge to anything—its variance explodes to infinity. The derivative \\(dB/dt\\) simply does not exist. This means: - ❌ We cannot draw tangent lines to \\(B(t)\\) - ❌ We cannot use the chain rule in its classical form - ❌ We cannot solve differential equations like \\(\\frac{dX}{dt} = \\sigma B(t)\\) using ordinary methods - ❌ The fundamental theorem of calculus doesn’t apply directly The verdict: Classical calculus is fundamentally incompatible with Brownian motion and other stochastic processes. We need a new calculus. 1.5.2 The Key Insight: Build from Changes, Not Slopes Here’s the conceptual breakthrough, first developed by Kiyoshi Itô in the 1940s: Instead of building calculus from derivatives (rates of change), we’ll build it from differentials (increments of change). In classical calculus, these two perspectives are equivalent via the differential: \\[df = f&#39;(t) \\, dt\\] But for stochastic processes, they’re not! While \\(dB/dt\\) doesn’t exist, the increment \\(dB\\) does exist and has a precise probabilistic meaning: \\[\\boxed{dB_t \\sim N(0, dt)}\\] This says: over an infinitesimal time interval of length \\(dt\\), the Brownian increment \\(dB_t\\) is normally distributed with mean zero and variance \\(dt\\). Why this works: We’re no longer asking “what is the slope at time \\(t\\)?” (which has no answer). Instead, we’re asking “what is the probability distribution of the change from \\(t\\) to \\(t + dt\\)?” (which does have an answer). This is the seed from which all of stochastic calculus grows. 1.5.3 The Arithmetic of Infinitesimals: \\((dB)^2 \\neq 0\\) In classical calculus, when working with a smooth function \\(f(t)\\), we treat \\((dt)^2\\) as negligible: \\[(dt)^2 = o(dt) \\approx 0\\] This is because \\((0.01)^2 = 0.0001\\) is much smaller than \\(0.01\\). As \\(dt \\to 0\\), the squared term vanishes faster. But Brownian motion breaks this rule. Let’s see why: Consider the square of a Brownian increment: \\[(dB_t)^2 = [B(t + dt) - B(t)]^2\\] Since \\(dB_t \\sim N(0, dt)\\), we can write \\(dB_t = \\sqrt{dt} \\cdot Z\\) where \\(Z \\sim N(0,1)\\). Therefore: \\[(dB_t)^2 = (\\sqrt{dt} \\cdot Z)^2 = dt \\cdot Z^2\\] Taking expectations: \\[\\mathbb{E}[(dB_t)^2] = dt \\cdot \\mathbb{E}[Z^2] = dt \\cdot 1 = dt\\] The shocking conclusion: \\((dB_t)^2\\) is not negligible—it’s of the same order as \\(dt\\) itself! In the language of stochastic calculus, we write: \\[\\boxed{(dB_t)^2 = dt}\\] This is a deterministic relationship (the randomness averages out), and it’s the signature rule of stochastic calculus. 1.5.4 Comparing Classical and Stochastic Infinitesimals Let’s make the contrast explicit. For a smooth function \\(x(t)\\) and Brownian motion \\(B(t)\\): Classical Calculus Stochastic Calculus \\(dx = x&#39;(t) \\, dt\\) exists \\(dB/dt\\) does not exist \\(dx \\sim O(dt)\\) \\(dB \\sim O(\\sqrt{dt})\\) \\((dx)^2 = O(dt^2) \\approx 0\\) \\((dB)^2 = dt \\neq 0\\) Paths are smooth Paths are jagged Finite variation Infinite variation The third row is particularly striking. Squaring a classical differential makes it negligible. Squaring a stochastic differential leaves it the same order of magnitude.  Heuristic Intuition: Think of \\(dB\\) as being “roughly of size \\(\\sqrt{dt}\\).” Then: - Classical: \\((dt)^2 \\sim dt \\cdot dt\\) (negligible) - Stochastic: \\((dB)^2 \\sim (\\sqrt{dt})^2 = dt\\) (non-negligible) This \\(\\sqrt{dt}\\) vs. \\(dt\\) distinction is what makes stochastic calculus fundamentally different. 1.5.5 Quadratic Variation: A New Concept This leads us to a notion that has no classical analog: quadratic variation. For a smooth function \\(f(t)\\) over \\([0, T]\\), partition the interval into \\(n\\) pieces and compute: \\[\\text{QV}[f] = \\lim_{n \\to \\infty} \\sum_{i=1}^{n} [f(t_i) - f(t_{i-1})]^2 = 0\\] The sum vanishes because smooth functions have finite total variation (they don’t wiggle infinitely much). But for Brownian motion: \\[\\text{QV}[B] = \\lim_{n \\to \\infty} \\sum_{i=1}^{n} [B(t_i) - B(t_{i-1})]^2 = T\\] Interpretation: Even though each individual increment \\(dB\\) is small (order \\(\\sqrt{dt}\\)), when you square them and add them up, you get something finite and deterministic—the elapsed time itself. In integral notation: \\[\\int_0^T (dB_t)^2 = \\int_0^T dt = T\\] This is written symbolically as: \\[\\langle B, B \\rangle_T = T\\] where \\(\\langle B, B \\rangle\\) denotes the quadratic variation process. 1.5.5.1 Why Quadratic Variation Matters The non-zero quadratic variation of Brownian motion has profound consequences: Itô’s Lemma: The stochastic chain rule will include a second-order correction term proportional to \\((dB)^2 = dt\\). This doesn’t appear in classical calculus because \\((dx)^2 = 0\\) there. Energy and volatility: In physics, quadratic variation relates to energy dissipation. In finance, it measures the accumulated volatility of a price path. Distinguishing processes: Two processes might have the same first-order behavior but different quadratic variations—this difference can be economically meaningful (e.g., distinguishing continuous vs. jump processes). No arbitrage: In financial mathematics, the quadratic variation appears in the change of measure techniques that underpin option pricing. (#fig:quad_var_demo)Approximating quadratic variation. As partition gets finer (more points), the sum of squared increments converges to elapsed time \\(T\\), not to zero. What the simulation shows: We partition \\([0, 1]\\) into \\(n = 10, 100, 1000, 10000\\) intervals and compute \\(\\sum [B(t_i) - B(t_{i-1})]^2\\). The sum converges to 1 (the elapsed time), confirming that quadratic variation is non-zero and equals the time interval. 1.5.6 A New Foundation for Calculus Let’s summarize the paradigm shift: Classical calculus: - Foundation: Derivative (slope) - Infinitesimal: \\(dx = f&#39;(t) \\, dt\\) - Second-order: \\((dx)^2 = 0\\) (negligible) - Integration: Area under curves - Applies to: Smooth, differentiable functions Stochastic calculus: - Foundation: Increment (change) - Infinitesimal: \\(dB_t \\sim N(0, dt)\\) - Second-order: \\((dB)^2 = dt\\) (non-negligible!) - Integration: Limit of Riemann-like sums with randomness - Applies to: Continuous but non-differentiable paths The absence of derivatives forces us to think differently, but it opens up a richer mathematical structure. We trade smoothness for randomness, and discover that randomness has its own beautiful calculus. 1.5.6.1 The Road Ahead With these foundations in place, we’re ready to build stochastic calculus: Stochastic integrals: What does \\(\\int_0^t f(s) \\, dB_s\\) mean when \\(dB\\) is random? Itô’s lemma: How do we differentiate \\(f(B_t, t)\\) when \\(B_t\\) has no derivative? Stochastic differential equations: How do we solve \\(dX_t = \\mu(X_t) \\, dt + \\sigma(X_t) \\, dB_t\\)? Each of these will leverage the fundamental property \\((dB)^2 = dt\\) in essential ways. The “crisis” of non-differentiability becomes an opportunity to discover new mathematics. As we’ll see, this isn’t just abstract theory—it’s the language in which modern finance, physics, and engineering describe uncertainty. "],["itô-integral-and-itôs-lemma.html", "Chapter 2 Itô Integral and Itô’s Lemma 2.1 The Challenge of Stochastic Integration 2.2 The Itô Integral 2.3 A Crucial Example: \\(\\int_0^t B(s) \\, dB(s)\\) 2.4 Quadratic Variation and the Formal Rule \\((dB)^2 = dt\\) 2.5 Itô’s Lemma: The Fundamental Theorem 2.6 Verification: Recovering Our Earlier Result 2.7 Example: The Exponential 2.8 General Itô’s Lemma 2.9 Why Itô’s Choice?", " Chapter 2 Itô Integral and Itô’s Lemma 2.1 The Challenge of Stochastic Integration In regular calculus, we integrate smooth functions: \\[\\int_0^t f(s) \\, ds = \\lim_{\\Delta s \\to 0} \\sum_{i} f(s_i) \\Delta s\\] For smooth functions \\(f\\), it doesn’t matter whether we evaluate at the left endpoint, right endpoint, or midpoint of each interval - we get the same answer in the limit. But what about: \\[\\int_0^t f(s) \\, dB(s) \\quad ?\\] This means integrating \\(f\\) with respect to Brownian motion. Instead of accumulating tiny areas \\(f(s_i) \\Delta s\\), we’re accumulating random contributions \\(f(s_i) \\Delta B_i\\) where \\(\\Delta B_i = B(s_{i+1}) - B(s_i)\\). 2.1.1 The Problem Because Brownian motion is so rough (nowhere differentiable), the choice of evaluation point matters critically! Different choices give different answers, even in the limit. This isn’t just a technical nuisance - it reflects a fundamental ambiguity about how to define integration with respect to a rough, random path. 2.2 The Itô Integral Kiyoshi Itô made a choice that turned out to be mathematically natural and practically useful: always evaluate at the left endpoint. 2.2.1 Definition The Itô integral is defined as: \\[\\int_0^t f(s) \\, dB(s) = \\lim_{n \\to \\infty} \\sum_{i=0}^{n-1} f(s_i) [B(s_{i+1}) - B(s_i)]\\] where \\(0 = s_0 &lt; s_1 &lt; \\cdots &lt; s_n = t\\) is a partition that gets progressively finer, and we use \\(f(s_i)\\) from the left of each interval. 2.2.2 Why the Left Endpoint? This choice makes \\(f(s_i)\\) independent of \\(\\Delta B_i = B(s_{i+1}) - B(s_i)\\), because \\(f(s_i)\\) depends only on information up to time \\(s_i\\), while \\(\\Delta B_i\\) is the future increment. This independence gives us beautiful properties: Martingale property: \\(\\int_0^t f(s) \\, dB(s)\\) is a martingale (under appropriate conditions on \\(f\\)) Zero expectation: \\(E\\left[\\int_0^t f(s) \\, dB(s)\\right] = 0\\) Isometry: \\(E\\left[\\left(\\int_0^t f(s) \\, dB(s)\\right)^2\\right] = E\\left[\\int_0^t f^2(s) \\, ds\\right]\\) The third property is called the Itô isometry and is fundamental for proving convergence. 2.3 A Crucial Example: \\(\\int_0^t B(s) \\, dB(s)\\) Let’s compute this integral using the definition. We want: \\[\\lim_{n \\to \\infty} \\sum_{i=0}^{n-1} B(s_i) [B(s_{i+1}) - B(s_i)]\\] Here’s a clever algebraic trick. Note that: \\[B^2(s_{i+1}) - B^2(s_i) = [B(s_{i+1}) - B(s_i)]^2 + 2B(s_i)[B(s_{i+1}) - B(s_i)]\\] Rearranging: \\[B(s_i)[B(s_{i+1}) - B(s_i)] = \\frac{1}{2}[B^2(s_{i+1}) - B^2(s_i)] - \\frac{1}{2}[B(s_{i+1}) - B(s_i)]^2\\] Summing over all intervals: \\[\\sum_{i=0}^{n-1} B(s_i) \\Delta B_i = \\frac{1}{2}[B^2(t) - B^2(0)] - \\frac{1}{2}\\sum_{i=0}^{n-1} (\\Delta B_i)^2\\] The first term telescopes to give \\(\\frac{1}{2}B^2(t)\\). But what about that second sum? 2.3.1 The Quadratic Variation Miracle Each \\((\\Delta B_i)^2\\) has expected value \\(E[(\\Delta B_i)^2] = s_{i+1} - s_i = \\Delta t_i\\). As the partition gets finer, by the law of large numbers: \\[\\sum_{i=0}^{n-1} (\\Delta B_i)^2 \\to t\\] This is the quadratic variation we mentioned earlier. Remarkably, it converges to the deterministic value \\(t\\)! Therefore: \\[\\boxed{\\int_0^t B(s) \\, dB(s) = \\frac{1}{2}B^2(t) - \\frac{1}{2}t}\\] 2.3.2 The Shock In regular calculus, \\(\\int_0^t x \\, dx = \\frac{1}{2}x^2\\). But here we get an extra \\(-\\frac{t}{2}\\) term! This correction term is the signature of stochastic calculus - it comes from the non-zero quadratic variation of Brownian motion. 2.4 Quadratic Variation and the Formal Rule \\((dB)^2 = dt\\) The key insight is: \\[\\sum_{i=0}^{n-1} (\\Delta B_i)^2 \\to t \\quad \\text{as } n \\to \\infty\\] In differential notation, we write this as the formal rule: \\[(dB)^2 = dt\\] This is not literally true (both sides are zero!), but it’s a mnemonic for the limiting behavior. 2.4.1 Multiplication Rules From \\((dB)^2 = dt\\), we can derive multiplication rules for stochastic differentials: Term Value Reason \\(dt \\cdot dt\\) \\(0\\) Second order in deterministic time \\(dt \\cdot dB\\) \\(0\\) Deterministic times random of order \\(\\sqrt{dt}\\) \\(dB \\cdot dB\\) \\(dt\\) Quadratic variation! These rules are essential for applying Itô’s lemma. 2.5 Itô’s Lemma: The Fundamental Theorem Now we come to the crown jewel - the chain rule for stochastic calculus. In regular calculus, if \\(x(t)\\) is differentiable and \\(f\\) is smooth: \\[\\frac{d}{dt}f(x(t)) = f&#39;(x(t)) \\cdot \\frac{dx}{dt}\\] Or in differential form: \\(df = f&#39;(x) \\, dx\\) Question: If \\(B(t)\\) is Brownian motion and \\(f\\) is smooth, what is \\(df(B(t))\\)? Naive guess: \\(df = f&#39;(B) \\, dB\\)? Wrong! 2.5.1 The Derivation Use Taylor expansion for small changes: \\[f(B(t + dt)) - f(B(t)) = f&#39;(B) \\cdot dB + \\frac{1}{2}f&#39;&#39;(B) \\cdot (dB)^2 + \\frac{1}{6}f&#39;&#39;&#39;(B) \\cdot (dB)^3 + \\cdots\\] In regular calculus, \\((dx)^2\\) and higher terms vanish as \\(dt \\to 0\\). But \\((dB)^2 = dt\\)! So the second-order term becomes: \\[\\frac{1}{2}f&#39;&#39;(B) \\cdot (dB)^2 = \\frac{1}{2}f&#39;&#39;(B) \\cdot dt\\] This term survives! The higher terms \\((dB)^3, (dB)^4, \\ldots\\) do vanish (they’re of order \\(dt^{3/2}, dt^2, \\ldots\\)). 2.5.2 Itô’s Lemma for \\(f(B(t))\\) \\[\\boxed{df(B) = f&#39;(B) \\, dB + \\frac{1}{2}f&#39;&#39;(B) \\, dt}\\] The extra \\(\\frac{1}{2}f&#39;&#39;(B) \\, dt\\) term is the Itô correction - the price we pay for the roughness of Brownian motion. 2.6 Verification: Recovering Our Earlier Result Let’s verify with \\(f(x) = x^2\\), so \\(f&#39;(x) = 2x\\) and \\(f&#39;&#39;(x) = 2\\). Itô’s lemma gives: \\[d(B^2) = 2B \\, dB + \\frac{1}{2} \\cdot 2 \\, dt = 2B \\, dB + dt\\] Integrating from 0 to \\(t\\): \\[B^2(t) - B^2(0) = 2\\int_0^t B(s) \\, dB(s) + t\\] Since \\(B(0) = 0\\): \\[B^2(t) = 2\\int_0^t B(s) \\, dB(s) + t\\] Therefore: \\[\\int_0^t B(s) \\, dB(s) = \\frac{1}{2}B^2(t) - \\frac{1}{2}t \\quad \\checkmark\\] Perfect match! 2.7 Example: The Exponential Take \\(f(x) = e^x\\), so \\(f&#39;(x) = f&#39;&#39;(x) = e^x\\). Itô’s lemma: \\[d(e^B) = e^B \\, dB + \\frac{1}{2}e^B \\, dt = e^B \\left(dB + \\frac{1}{2}dt\\right)\\] Integrating: \\[e^{B(t)} = 1 + \\int_0^t e^{B(s)} \\, dB(s) + \\frac{1}{2}\\int_0^t e^{B(s)} \\, ds\\] This is an integral equation for the exponential of Brownian motion. Taking expectations (the stochastic integral has zero mean): \\[E[e^{B(t)}] = 1 + \\frac{1}{2}\\int_0^t E[e^{B(s)}] \\, ds\\] Let \\(m(t) = E[e^{B(t)}]\\). Then \\(m&#39;(t) = \\frac{1}{2}m(t)\\) with \\(m(0) = 1\\). Solution: \\(E[e^{B(t)}] = e^{t/2}\\) You can verify this directly: since \\(B(t) \\sim N(0,t)\\), the moment generating function gives \\(E[e^{B(t)}] = e^{t/2}\\). ✓ 2.8 General Itô’s Lemma For a function \\(f(t, x)\\) of both time and space, and a process \\(X(t)\\): \\[\\boxed{df(t, X) = \\frac{\\partial f}{\\partial t}dt + \\frac{\\partial f}{\\partial x}dX + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}(dX)^2}\\] This is the form we’ll use most often in applications. 2.8.1 The Pattern To apply Itô’s lemma: Identify the function \\(f\\) and the stochastic process \\(X\\) Compute the partial derivatives: \\(\\frac{\\partial f}{\\partial t}\\), \\(\\frac{\\partial f}{\\partial x}\\), \\(\\frac{\\partial^2 f}{\\partial x^2}\\) Compute \\((dX)^2\\) using the multiplication rules Substitute everything into the formula This becomes second nature with practice! 2.9 Why Itô’s Choice? Other choices for the evaluation point lead to other stochastic calculi: Stratonovich integral: Uses the midpoint, gives different rules Backward integral: Uses the right endpoint Itô’s calculus won out because: Martingale property: Itô integrals are martingales Natural for finance: Fits the “no-anticipation” principle Connection to PDEs: Leads naturally to Feynman-Kac Computational advantage: Easier to simulate The Itô convention is now standard in probability, finance, and most applications. "],["stochastic-differential-equations.html", "Chapter 3 Stochastic Differential Equations 3.1 Introduction to SDEs 3.2 Geometric Brownian Motion 3.3 Ornstein-Uhlenbeck Process 3.4 General Strategy for Solving SDEs 3.5 Linear SDEs 3.6 Existence and Uniqueness 3.7 Strong vs. Weak Solutions 3.8 Multidimensional SDEs", " Chapter 3 Stochastic Differential Equations 3.1 Introduction to SDEs A stochastic differential equation (SDE) describes how a random process evolves over time, combining deterministic trends with random fluctuations. The general form is: \\[dX(t) = \\mu(t, X) \\, dt + \\sigma(t, X) \\, dB(t)\\] where: \\(\\mu(t, X)\\) is the drift coefficient - the deterministic trend \\(\\sigma(t, X)\\) is the diffusion coefficient (or volatility) - controls the random fluctuations \\(B(t)\\) is standard Brownian motion This differential equation is shorthand for the integral equation: \\[X(t) = X(0) + \\int_0^t \\mu(s, X(s)) \\, ds + \\int_0^t \\sigma(s, X(s)) \\, dB(s)\\] The first integral is ordinary (deterministic), the second is an Itô integral (random). 3.2 Geometric Brownian Motion The most famous SDE in finance models stock prices: \\[dS = \\mu S \\, dt + \\sigma S \\, dB\\] where \\(\\mu\\) and \\(\\sigma\\) are constants. 3.2.1 Interpretation Rewrite as: \\[\\frac{dS}{S} = \\mu \\, dt + \\sigma \\, dB\\] The return \\(dS/S\\) has two components: Deterministic drift: \\(\\mu \\, dt\\) per unit time Random shock: \\(\\sigma \\, dB\\) with volatility \\(\\sigma\\) This says returns (not prices!) have a constant drift and volatility. 3.2.2 Solving GBM We can’t just “integrate” the SDE directly. Instead, we use Itô’s lemma to find the right transformation! Strategy: Try \\(f(S) = \\log S\\). Then: - \\(f&#39;(S) = 1/S\\) - \\(f&#39;&#39;(S) = -1/S^2\\) From the SDE: \\(dS = \\mu S \\, dt + \\sigma S \\, dB\\) Therefore: \\((dS)^2 = (\\mu S \\, dt + \\sigma S \\, dB)^2 = \\sigma^2 S^2 (dB)^2 = \\sigma^2 S^2 \\, dt\\) (The \\(dt \\cdot dB\\) and \\((dt)^2\\) terms vanish.) By Itô’s lemma: \\[d(\\log S) = \\frac{1}{S} dS + \\frac{1}{2}\\left(-\\frac{1}{S^2}\\right)(dS)^2\\] \\[= \\frac{1}{S}(\\mu S \\, dt + \\sigma S \\, dB) - \\frac{1}{2} \\cdot \\frac{1}{S^2} \\cdot \\sigma^2 S^2 \\, dt\\] \\[= \\mu \\, dt + \\sigma \\, dB - \\frac{\\sigma^2}{2} \\, dt\\] \\[= \\left(\\mu - \\frac{\\sigma^2}{2}\\right) dt + \\sigma \\, dB\\] This is linear in \\(\\log S\\)! Integrating from 0 to \\(t\\): \\[\\log S(t) - \\log S(0) = \\left(\\mu - \\frac{\\sigma^2}{2}\\right)t + \\sigma B(t)\\] Exponentiating: \\[\\boxed{S(t) = S(0) \\exp\\left[\\left(\\mu - \\frac{\\sigma^2}{2}\\right)t + \\sigma B(t)\\right]}\\] 3.2.3 Key Observations Always positive: \\(S(t) &gt; 0\\) always (good for stock prices!) Log-normal: \\(\\log S(t)\\) is normally distributed Itô correction: The drift in the exponent is \\(\\mu - \\sigma^2/2\\), not \\(\\mu\\) Expected value: \\(E[S(t)] = S(0)e^{\\mu t}\\) (using the moment generating function) Median: \\(\\text{median}[S(t)] = S(0)e^{(\\mu - \\sigma^2/2)t}\\) The difference between \\(\\mu\\) and \\(\\mu - \\sigma^2/2\\) is sometimes called Jensen’s inequality correction or the convexity adjustment. 3.2.4 The Itô Correction Explained Why the \\(-\\sigma^2/2\\) term? The exponential function is convex. Because of volatility, \\(S(t)\\) spends more time in regions where the exponential curves upward. To maintain the correct expected drift rate, we need to adjust downward by \\(\\sigma^2/2\\). This is a general feature: non-linear transformations of stochastic processes pick up correction terms proportional to the second derivative (curvature). 3.3 Ornstein-Uhlenbeck Process This SDE models mean reversion - a tendency to return to a long-term average: \\[dX = -\\theta X \\, dt + \\sigma \\, dB\\] where \\(\\theta &gt; 0\\) is the mean reversion speed. 3.3.1 Interpretation When \\(X &gt; 0\\): drift is negative (pulled toward zero) When \\(X &lt; 0\\): drift is positive (pushed toward zero) Strength of pull proportional to distance from zero This models: - Interest rates (tend to revert to long-term average) - Commodity prices (mean reversion due to supply/demand) - Temperature (seasonal mean reversion) 3.3.2 Solving the OU Process Try the transformation \\(f(t, X) = e^{\\theta t} X\\). Partial derivatives: - \\(\\frac{\\partial f}{\\partial t} = \\theta e^{\\theta t} X\\) - \\(\\frac{\\partial f}{\\partial X} = e^{\\theta t}\\) - \\(\\frac{\\partial^2 f}{\\partial X^2} = 0\\) By Itô’s lemma: \\[d(e^{\\theta t} X) = \\theta e^{\\theta t} X \\, dt + e^{\\theta t} dX + 0\\] Substitute \\(dX = -\\theta X \\, dt + \\sigma \\, dB\\): \\[d(e^{\\theta t} X) = \\theta e^{\\theta t} X \\, dt + e^{\\theta t}(-\\theta X \\, dt + \\sigma \\, dB)\\] \\[= \\sigma e^{\\theta t} \\, dB\\] The drift terms cancel! Integrating: \\[e^{\\theta t} X(t) - X(0) = \\sigma \\int_0^t e^{\\theta s} \\, dB(s)\\] Therefore: \\[\\boxed{X(t) = X(0)e^{-\\theta t} + \\sigma \\int_0^t e^{-\\theta(t-s)} \\, dB(s)}\\] 3.3.3 Properties of the Solution Exponential decay: The initial condition \\(X(0)\\) decays as \\(e^{-\\theta t}\\) Half-life: Time to halve: \\(t_{1/2} = \\frac{\\log 2}{\\theta}\\) Gaussian: \\(X(t)\\) is normally distributed (it’s a linear combination of Brownian increments) Mean: \\(E[X(t)] = X(0)e^{-\\theta t} \\to 0\\) as \\(t \\to \\infty\\) Variance: \\(\\text{Var}(X(t)) = \\frac{\\sigma^2}{2\\theta}(1 - e^{-2\\theta t}) \\to \\frac{\\sigma^2}{2\\theta}\\) as \\(t \\to \\infty\\) The process reaches a stationary distribution \\(N(0, \\sigma^2/(2\\theta))\\) as \\(t \\to \\infty\\). 3.3.4 Generalization: OU with Mean \\(\\mu\\) The SDE: \\[dX = \\theta(\\mu - X) \\, dt + \\sigma \\, dB\\] reverts to a non-zero mean \\(\\mu\\). The solution is: \\[X(t) = \\mu + [X(0) - \\mu]e^{-\\theta t} + \\sigma \\int_0^t e^{-\\theta(t-s)} \\, dB(s)\\] Stationary distribution: \\(N(\\mu, \\sigma^2/(2\\theta))\\) 3.4 General Strategy for Solving SDEs Not all SDEs have closed-form solutions, but when they do, the strategy is: Guess a transformation \\(f(X)\\) or \\(f(t, X)\\) that might linearize or simplify things Apply Itô’s lemma to find \\(df\\) Hope that \\(df\\) is simpler (ideally linear or separable) Integrate and solve for \\(f\\) Transform back to find \\(X\\) Common tricks: - For multiplicative noise: try \\(\\log X\\) - For mean reversion: try \\(e^{\\theta t} X\\) - For time-dependent drift: try integrating factors - For Bessel processes: try \\(X^2\\) This is an art! Intuition comes with practice. 3.5 Linear SDEs SDEs of the form: \\[dX = [a(t) + b(t)X] \\, dt + [c(t) + d(t)X] \\, dB\\] where \\(a, b, c, d\\) are deterministic functions, can always be solved using integrating factors. The solution involves: 1. Solving the homogeneous equation 2. Variation of parameters for the particular solution 3. Combining with the stochastic integral This parallels the theory of linear ODEs, but with stochastic integrals replacing ordinary integrals. 3.6 Existence and Uniqueness When does an SDE have a solution? When is it unique? Theorem (Existence and Uniqueness): If \\(\\mu(t, x)\\) and \\(\\sigma(t, x)\\) satisfy: Lipschitz condition: There exists \\(K &gt; 0\\) such that \\[|\\mu(t,x) - \\mu(t,y)| + |\\sigma(t,x) - \\sigma(t,y)| \\leq K|x - y|\\] for all \\(t, x, y\\) Linear growth: There exists \\(C &gt; 0\\) such that \\[|\\mu(t,x)| + |\\sigma(t,x)| \\leq C(1 + |x|)\\] for all \\(t, x\\) Then the SDE has a unique strong solution for any initial condition \\(X(0)\\). These conditions ensure the drift and diffusion are “nice enough” - not too wild or growing too fast. 3.7 Strong vs. Weak Solutions Strong solution: Constructed pathwise on a given probability space with a given Brownian motion Weak solution: The probability distribution of the solution is specified, but the construction may vary Most applications in finance use weak solutions - we care about distributions of prices, not individual paths. 3.8 Multidimensional SDEs SDEs can be vectors: \\[dX_i = \\mu_i(t, \\mathbf{X}) \\, dt + \\sum_{j=1}^d \\sigma_{ij}(t, \\mathbf{X}) \\, dB_j\\] where \\(\\mathbf{X} = (X_1, \\ldots, X_n)\\) and \\(B_1, \\ldots, B_d\\) are independent Brownian motions. The matrix \\(\\sigma = (\\sigma_{ij})\\) is the diffusion matrix. The covariance structure is: \\[d\\langle X_i, X_j \\rangle = \\sum_{k=1}^d \\sigma_{ik} \\sigma_{jk} \\, dt = (\\sigma \\sigma^T)_{ij} \\, dt\\] Multidimensional Itô’s lemma becomes: \\[df(\\mathbf{X}) = \\sum_i \\frac{\\partial f}{\\partial x_i} dX_i + \\frac{1}{2}\\sum_{i,j} \\frac{\\partial^2 f}{\\partial x_i \\partial x_j} d\\langle X_i, X_j \\rangle\\] This is essential for modeling portfolios, interest rate curves, and other multivariate phenomena. "],["feynman-kac-and-pdes.html", "Chapter 4 Feynman-Kac and PDEs 4.1 The Bridge Between Probability and Analysis 4.2 The Backward Kolmogorov Equation 4.3 Example: The Heat Equation 4.4 The Black-Scholes PDE 4.5 The Forward Kolmogorov Equation 4.6 Feynman-Kac Formula (General Version) 4.7 Applications 4.8 Numerical Methods 4.9 Summary", " Chapter 4 Feynman-Kac and PDEs 4.1 The Bridge Between Probability and Analysis One of the most beautiful results in mathematics connects two seemingly different worlds: Stochastic differential equations (SDEs) - the probabilistic world Partial differential equations (PDEs) - the analytical world This connection, known as the Feynman-Kac formula, allows us to: - Solve PDEs by simulating random processes (Monte Carlo) - Solve SDEs by solving PDEs (numerical PDE methods) - Gain intuition about both simultaneously 4.2 The Backward Kolmogorov Equation Consider an SDE: \\[dX(t) = \\mu(X) \\, dt + \\sigma(X) \\, dB(t)\\] Define the function: \\[u(t, x) = E[g(X(T)) \\mid X(t) = x]\\] This represents the expected value of some payoff function \\(g\\) at terminal time \\(T\\), given that the process is at position \\(x\\) at time \\(t\\). Question: What PDE does \\(u(t,x)\\) satisfy? 4.2.1 Heuristic Derivation Apply Itô’s lemma to \\(u(t, X(t))\\): \\[du = \\frac{\\partial u}{\\partial t}dt + \\frac{\\partial u}{\\partial x}dX + \\frac{1}{2}\\frac{\\partial^2 u}{\\partial x^2}(dX)^2\\] Substitute \\(dX = \\mu \\, dt + \\sigma \\, dB\\) and \\((dX)^2 = \\sigma^2 \\, dt\\): \\[du = \\left[\\frac{\\partial u}{\\partial t} + \\mu\\frac{\\partial u}{\\partial x} + \\frac{1}{2}\\sigma^2\\frac{\\partial^2 u}{\\partial x^2}\\right]dt + \\sigma\\frac{\\partial u}{\\partial x}dB\\] Integrate from \\(t\\) to \\(T\\) and take expectations. The stochastic integral has zero expectation, so: \\[E[u(T, X(T))] - u(t, x) = E\\left[\\int_t^T \\left(\\frac{\\partial u}{\\partial s} + \\mu\\frac{\\partial u}{\\partial x} + \\frac{1}{2}\\sigma^2\\frac{\\partial^2 u}{\\partial x^2}\\right)ds\\right]\\] At terminal time: \\(u(T, X(T)) = g(X(T))\\) by definition. For this to hold for all paths, we need: \\[\\boxed{\\frac{\\partial u}{\\partial t} + \\mu(x)\\frac{\\partial u}{\\partial x} + \\frac{1}{2}\\sigma^2(x)\\frac{\\partial^2 u}{\\partial x^2} = 0}\\] with boundary condition \\(u(T, x) = g(x)\\). This is the backward Kolmogorov equation (also called the Fokker-Planck backward equation). 4.3 Example: The Heat Equation Take the simplest SDE: \\(dX = dB\\) (pure Brownian motion, \\(\\mu = 0\\), \\(\\sigma = 1\\)). The backward equation becomes: \\[\\frac{\\partial u}{\\partial t} + \\frac{1}{2}\\frac{\\partial^2 u}{\\partial x^2} = 0\\] Change time direction by setting \\(\\tau = T - t\\): \\[\\boxed{\\frac{\\partial u}{\\partial \\tau} = \\frac{1}{2}\\frac{\\partial^2 u}{\\partial x^2}}\\] This is the heat equation! 4.3.1 Probabilistic Interpretation The solution to the heat equation with initial condition \\(u(0, x) = g(x)\\) is: \\[u(\\tau, x) = E[g(X(\\tau)) \\mid X(0) = x] = \\int_{-\\infty}^{\\infty} g(y) \\frac{1}{\\sqrt{2\\pi\\tau}} e^{-(y-x)^2/(2\\tau)} dy\\] The heat kernel \\(\\frac{1}{\\sqrt{2\\pi\\tau}} e^{-(y-x)^2/(2\\tau)}\\) is precisely the transition density of Brownian motion! Deep insight: Heat diffusion is mathematically identical to Brownian motion. Temperature spreads like a random walk. 4.4 The Black-Scholes PDE Now consider geometric Brownian motion: \\[dS = \\mu S \\, dt + \\sigma S \\, dB\\] For a derivative with payoff \\(g(S(T))\\) at time \\(T\\), we want the price: \\[V(t, S) = E[g(S(T)) \\mid S(t) = S]\\] But we need to account for discounting at the risk-free rate \\(r\\). In a risk-neutral world (more on this later), we replace \\(\\mu\\) with \\(r\\) and define: \\[V(t, S) = e^{-r(T-t)}E^{\\mathbb{Q}}[g(S(T)) \\mid S(t) = S]\\] Let \\(u(t, S) = e^{-r(T-t)}V(t, S)\\) to factor out the discounting. By Itô’s lemma and similar arguments: \\[\\boxed{\\frac{\\partial V}{\\partial t} + rS\\frac{\\partial V}{\\partial S} + \\frac{1}{2}\\sigma^2 S^2\\frac{\\partial^2 V}{\\partial S^2} = rV}\\] with terminal condition \\(V(T, S) = g(S)\\). This is the Black-Scholes PDE! 4.4.1 Solving for a European Call For \\(g(S) = \\max(S - K, 0)\\), the solution is: \\[V(t, S) = S\\Phi(d_1) - Ke^{-r(T-t)}\\Phi(d_2)\\] where: \\[d_1 = \\frac{\\log(S/K) + (r + \\sigma^2/2)(T-t)}{\\sigma\\sqrt{T-t}}, \\quad d_2 = d_1 - \\sigma\\sqrt{T-t}\\] We’ll derive this in the next chapter using risk-neutral pricing. 4.5 The Forward Kolmogorov Equation There’s also a forward equation that describes how the probability density \\(p(t, x)\\) of \\(X(t)\\) evolves: \\[\\frac{\\partial p}{\\partial t} = -\\frac{\\partial}{\\partial x}[\\mu(x)p] + \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}[\\sigma^2(x)p]\\] This is the forward Kolmogorov equation (or Fokker-Planck forward equation). 4.5.1 The Duality Backward equation: Expects values along future paths (pricing) Forward equation: Probability density evolution (statistical mechanics) These are dual perspectives on the same stochastic process. 4.6 Feynman-Kac Formula (General Version) The most general form handles running costs and discounting: Theorem: Consider the SDE \\(dX = \\mu(X) \\, dt + \\sigma(X) \\, dB\\) with initial condition \\(X(t) = x\\). Define: \\[u(t, x) = E\\left[g(X(T))e^{-\\int_t^T c(X(s))ds} + \\int_t^T f(X(s))e^{-\\int_t^s c(X(r))dr}ds \\mid X(t) = x\\right]\\] Then \\(u\\) satisfies: \\[\\frac{\\partial u}{\\partial t} + \\mu\\frac{\\partial u}{\\partial x} + \\frac{1}{2}\\sigma^2\\frac{\\partial^2 u}{\\partial x^2} - c(x)u + f(x) = 0\\] with \\(u(T, x) = g(x)\\). Here: - \\(c(x)\\) is a discount rate (e.g., interest rate) - \\(f(x)\\) is a running payoff (e.g., dividends) - \\(g(x)\\) is terminal payoff 4.7 Applications 4.7.1 Option Pricing The Feynman-Kac formula underpins all of option pricing theory: - Price = expected discounted payoff under risk-neutral measure - Can solve either the PDE or simulate the SDE 4.7.2 Statistical Mechanics In physics, the heat equation describes: - Temperature diffusion - Particle density evolution - Quantum mechanics (Schrödinger equation with imaginary time) 4.7.3 Control Theory Optimal control problems (Hamilton-Jacobi-Bellman equations) connect to SDEs through Feynman-Kac. 4.7.4 Biology Population dynamics, gene frequency evolution, and neural activity models all use this connection. 4.8 Numerical Methods 4.8.1 Monte Carlo Simulation To compute \\(u(t,x) = E[g(X(T)) \\mid X(t) = x]\\): Simulate many paths of the SDE starting from \\(X(t) = x\\) Evaluate \\(g(X(T))\\) for each path Average the results Advantages: Easy to implement, works in high dimensions Disadvantages: Slow convergence (\\(\\mathcal{O}(1/\\sqrt{N})\\)), difficult for early exercise 4.8.2 PDE Methods Discretize the PDE on a grid using: - Finite differences (explicit, implicit, Crank-Nicolson) - Finite elements - Spectral methods Advantages: Fast, handles early exercise naturally Disadvantages: Curse of dimensionality, boundary conditions tricky 4.8.3 Hybrid Methods Modern approaches combine both: - Use PDE methods when low-dimensional - Use Monte Carlo when high-dimensional - Use sparse grids, reduced basis methods, etc. 4.9 Summary The Feynman-Kac connection is profound: SDE: dX = μdt + σdB ↓ (Itô&#39;s lemma) PDE: ∂u/∂t + μ∂u/∂x + ½σ²∂²u/∂x² = 0 ↕ (Feynman-Kac) Probabilistic representation: u(t,x) = E[g(X(T)) | X(t)=x] This bridges: - Probability ↔︎ Analysis - Random walks ↔︎ Differential equations - Simulation ↔︎ Analytic solutions - Physics ↔︎ Finance It’s one of the most beautiful and useful results in applied mathematics. "],["risk-neutral-pricing-and-martingales.html", "Chapter 5 Risk-Neutral Pricing and Martingales 5.1 Martingales: Fair Games 5.2 The Fundamental Theorem of Asset Pricing 5.3 Risk-Neutral Pricing Formula 5.4 Why Does This Work? 5.5 Example: Forward Contracts 5.6 Change of Numeraire 5.7 Market Price of Risk 5.8 Incomplete Markets 5.9 Summary", " Chapter 5 Risk-Neutral Pricing and Martingales 5.1 Martingales: Fair Games A stochastic process \\(M(t)\\) is a martingale if: \\[E[M(t) \\mid \\mathcal{F}_s] = M(s) \\quad \\text{for all } t \\geq s\\] where \\(\\mathcal{F}_s\\) represents all information up to time \\(s\\). Intuitive meaning: The best prediction of tomorrow’s value is today’s value. No drift, just random fluctuations. It’s a “fair game” - you can’t make money on average. Key property: If \\(M(t)\\) is a martingale, then \\(E[M(t)] = E[M(0)]\\) for all \\(t\\). 5.1.1 Examples Brownian motion: \\(B(t)\\) is a martingale Itô integral: \\(\\int_0^t f(s) \\, dB(s)\\) is a martingale (if \\(f\\) satisfies certain conditions) Exponential martingale: \\(\\exp(\\sigma B(t) - \\frac{1}{2}\\sigma^2 t)\\) is a martingale Casino winnings: Your wealth in a fair game 5.2 The Fundamental Theorem of Asset Pricing This is the nuclear bomb of mathematical finance: Theorem: A market is arbitrage-free if and only if there exists a probability measure \\(\\mathbb{Q}\\) (the risk-neutral measure) under which all discounted asset prices are martingales. Let me unpack this carefully. 5.2.1 What’s Arbitrage? An arbitrage is a “free lunch” - a trading strategy that: 1. Costs nothing to set up 2. Never loses money 3. Sometimes makes money Markets without arbitrage are called arbitrage-free. This is a minimal rationality assumption. 5.2.2 The Risk-Neutral Measure In the real world (measure \\(\\mathbb{P}\\)), a stock might follow: \\[dS = \\mu S \\, dt + \\sigma S \\, dB\\] where \\(\\mu\\) is the real drift (could be 8%, 12%, whatever). The discounted price is \\(\\tilde{S}(t) = e^{-rt}S(t)\\) where \\(r\\) is the risk-free rate. By Itô’s lemma: \\[d\\tilde{S} = \\tilde{S}[(\\mu - r)dt + \\sigma \\, dB]\\] This has drift \\(\\mu - r\\). If \\(\\mu \\neq r\\), this is NOT a martingale under \\(\\mathbb{P}\\). The trick: Change to a different probability measure \\(\\mathbb{Q}\\) where the drift vanishes! 5.2.3 Girsanov’s Theorem Under \\(\\mathbb{Q}\\), we define a new Brownian motion: \\[\\tilde{B}(t) = B(t) + \\frac{\\mu - r}{\\sigma}t\\] By Girsanov’s theorem (deep measure theory), \\(\\tilde{B}(t)\\) is a Brownian motion under \\(\\mathbb{Q}\\). Then under \\(\\mathbb{Q}\\): \\[d\\tilde{S} = \\tilde{S}\\sigma \\, d\\tilde{B}\\] No drift! The discounted stock price is a martingale under \\(\\mathbb{Q}\\). 5.3 Risk-Neutral Pricing Formula Since \\(\\tilde{S}(t) = e^{-rt}S(t)\\) is a \\(\\mathbb{Q}\\)-martingale: \\[e^{-rt}S(t) = E^{\\mathbb{Q}}[e^{-rT}S(T) \\mid \\mathcal{F}_t]\\] For a derivative with payoff \\(g(S(T))\\) at time \\(T\\), no-arbitrage requires: \\[\\boxed{V(t) = e^{-r(T-t)}E^{\\mathbb{Q}}[g(S(T)) \\mid S(t)]}\\] This is the universal pricing formula! 5.3.1 The Miracle The real drift \\(\\mu\\) doesn’t appear! Risk preferences are already encoded in \\(S(t)\\) Only need: \\(S(t)\\), \\(r\\), \\(\\sigma\\), and payoff \\(g\\) Under \\(\\mathbb{Q}\\), assets grow at rate \\(r\\) (not \\(\\mu\\)): \\[dS = rS \\, dt + \\sigma S \\, d\\tilde{B}\\] This is why it’s called “risk-neutral” - it’s as if investors are indifferent to risk. 5.4 Why Does This Work? The key insight: replication. If you can replicate the derivative’s payoff using the underlying asset, then to avoid arbitrage, the derivative’s price must equal the replication cost. The risk-neutral measure emerges from imposing no-arbitrage across all possible replication strategies. 5.5 Example: Forward Contracts A forward contract obliges you to buy stock at price \\(K\\) at time \\(T\\). Payoff: \\(S(T) - K\\). Price: \\[V(t) = e^{-r(T-t)}E^{\\mathbb{Q}}[S(T) - K]\\] \\[= e^{-r(T-t)}[E^{\\mathbb{Q}}[S(T)] - K]\\] \\[= e^{-r(T-t)}[S(t)e^{r(T-t)} - K]\\] \\[= S(t) - Ke^{-r(T-t)}\\] The forward price (fair delivery price) is \\(F = S(t)e^{r(T-t)}\\). 5.6 Change of Numeraire You can use any traded asset as the “numeraire” (unit of account). If you use asset \\(N(t)\\) as numeraire, there exists a measure \\(\\mathbb{Q}^N\\) under which all prices relative to \\(N(t)\\) are martingales: \\[\\frac{S(t)}{N(t)} \\text{ is a } \\mathbb{Q}^N\\text{-martingale}\\] Common choices: - Money market account: \\(N(t) = e^{rt}\\) → standard risk-neutral measure - Zero-coupon bond: Useful for interest rate derivatives - Stock itself: Useful for options on options This technique is powerful for simplifying derivative pricing. 5.7 Market Price of Risk The drift shift from \\(\\mathbb{P}\\) to \\(\\mathbb{Q}\\) is governed by the market price of risk \\(\\lambda\\): \\[\\lambda = \\frac{\\mu - r}{\\sigma}\\] This measures the excess return per unit of volatility. Under \\(\\mathbb{Q}\\): \\[d\\tilde{B} = dB + \\lambda \\, dt\\] Different assets may have different market prices of risk. In a complete market, all risks are spanned by traded assets, so there’s a unique \\(\\mathbb{Q}\\). 5.8 Incomplete Markets If not all risks can be hedged (e.g., jumps, stochastic volatility without tradable volatility derivatives), the market is incomplete. Then: - Multiple risk-neutral measures exist - No unique price for derivatives - Need to choose \\(\\mathbb{Q}\\) based on additional criteria (e.g., minimize risk, match market prices) This is a major research area in quantitative finance. 5.9 Summary The martingale approach to pricing: Identify the source of randomness (Brownian motions) Find the risk-neutral measure (Girsanov theorem) Price as discounted expectation under \\(\\mathbb{Q}\\) This elegant framework unifies all of derivative pricing and connects probability theory to finance in a profound way. "],["black-scholes-theory.html", "Chapter 6 Black-Scholes Theory 6.1 The Black-Scholes Formula 6.2 The Greeks 6.3 Delta Hedging 6.4 Put-Call Parity 6.5 Implied Volatility 6.6 American Options 6.7 Extensions 6.8 Limitations of Black-Scholes", " Chapter 6 Black-Scholes Theory 6.1 The Black-Scholes Formula For a European call option with strike \\(K\\) and maturity \\(T\\), the price at time \\(t\\) with stock price \\(S\\) is: \\[\\boxed{C(t, S) = S\\Phi(d_1) - Ke^{-r(T-t)}\\Phi(d_2)}\\] where: \\[d_1 = \\frac{\\log(S/K) + (r + \\sigma^2/2)(T-t)}{\\sigma\\sqrt{T-t}}, \\quad d_2 = d_1 - \\sigma\\sqrt{T-t}\\] and \\(\\Phi\\) is the standard normal CDF. 6.1.1 Derivation Under the risk-neutral measure, stock price evolves as: \\[S(T) = S(t)\\exp\\left[\\left(r - \\frac{\\sigma^2}{2}\\right)(T-t) + \\sigma\\sqrt{T-t}Z\\right]\\] where \\(Z \\sim N(0,1)\\). The call price is: \\[C = e^{-r(T-t)}E^{\\mathbb{Q}}[\\max(S(T) - K, 0)]\\] After working through the integral (completing the square), we obtain the formula above. 6.1.2 Interpretation \\[C = S\\Phi(d_1) - Ke^{-r(T-t)}\\Phi(d_2)\\] \\(S\\Phi(d_1)\\): Expected present value of stock if exercised \\(Ke^{-r(T-t)}\\Phi(d_2)\\): Expected present value of strike payment \\(\\Phi(d_2)\\): Risk-neutral probability option finishes in-the-money \\(\\Phi(d_1)\\): “Delta” of the option (hedge ratio) 6.2 The Greeks The Greeks measure sensitivities of option prices to various parameters. They’re essential for risk management and hedging. 6.2.1 Delta (\\(\\Delta\\)) \\[\\Delta = \\frac{\\partial C}{\\partial S} = \\Phi(d_1)\\] Interpretation: - How much the option price changes per $1 change in stock price - Hedge ratio: to hedge a short call, buy \\(\\Delta\\) shares - Ranges from 0 (deep out-of-money) to 1 (deep in-the-money) 6.2.2 Gamma (\\(\\Gamma\\)) \\[\\Gamma = \\frac{\\partial^2 C}{\\partial S^2} = \\frac{\\phi(d_1)}{S\\sigma\\sqrt{T-t}}\\] where \\(\\phi\\) is the standard normal PDF. Interpretation: - Rate of change of Delta - Measures convexity of option price - Maximum at-the-money - Hedging \\(\\Gamma\\) is expensive (requires frequent rebalancing) 6.2.3 Vega (\\(\\mathcal{V}\\)) \\[\\mathcal{V} = \\frac{\\partial C}{\\partial \\sigma} = S\\phi(d_1)\\sqrt{T-t}\\] Interpretation: - Sensitivity to volatility - Options are “long volatility” - gain value when \\(\\sigma\\) increases - Maximum at-the-money - Long-dated options have more Vega 6.2.4 Theta (\\(\\Theta\\)) \\[\\Theta = \\frac{\\partial C}{\\partial t} = -\\frac{S\\phi(d_1)\\sigma}{2\\sqrt{T-t}} - rKe^{-r(T-t)}\\Phi(d_2)\\] Interpretation: - Time decay - value lost per day - Usually negative for long options (you lose time value) - Accelerates as expiration approaches 6.2.5 Rho (\\(\\rho\\)) \\[\\rho = \\frac{\\partial C}{\\partial r} = K(T-t)e^{-r(T-t)}\\Phi(d_2)\\] Interpretation: - Sensitivity to interest rates - Usually less important than other Greeks - More relevant for long-dated options 6.2.6 The Greeks Relationship They satisfy the Black-Scholes PDE: \\[\\Theta + \\frac{1}{2}\\sigma^2 S^2\\Gamma + rS\\Delta - rC = 0\\] This connects time decay, convexity, and delta in a beautiful way. 6.3 Delta Hedging You’re a market maker who sold a call option. How to hedge the risk? 6.3.1 The Strategy At time \\(t\\): Hold \\(\\Delta(t) = \\Phi(d_1)\\) shares of stock As stock moves: Continuously rebalance to maintain \\(\\Delta(t)\\) shares If hedged perfectly with correct volatility: Earn the risk-free rate 6.3.2 Discrete Hedging P&amp;L Over small time \\(dt\\), the P&amp;L is approximately: \\[dP\\&amp;L \\approx \\frac{1}{2}\\Gamma(dS)^2 - \\Theta \\, dt\\] \\((dS)^2\\) term: Realized variance \\(\\Theta\\) term: Time decay If realized volatility = implied volatility used for pricing, these balance out. 6.3.3 The Catch In practice: - Can’t rebalance continuously (transaction costs) - Don’t know true volatility in advance - If realized vol \\(\\neq\\) implied vol, you make/lose money This is why options trading is essentially trading volatility! 6.4 Put-Call Parity For European options with same strike and maturity: \\[C - P = S - Ke^{-r(T-t)}\\] Proof: Both sides have payoff \\(S(T) - K\\) at maturity. By no-arbitrage, they must have equal value today. Uses: - Price puts from calls (or vice versa) - Identify arbitrage opportunities - Understand synthetic positions 6.5 Implied Volatility The market quotes option prices, not volatilities. Implied volatility is the \\(\\sigma\\) that makes the Black-Scholes formula match the market price: \\[C_{\\text{market}} = C_{BS}(S, K, T, r, \\sigma_{implied})\\] 6.5.1 The Volatility Smile In practice, implied volatility varies with strike: - Equity markets: Volatility skew (higher for low strikes) - FX markets: Volatility smile (higher for extreme strikes) This violates Black-Scholes assumptions! Real markets have: - Fat tails (more crashes than log-normal predicts) - Stochastic volatility - Jumps Modern models address these issues. 6.6 American Options American options can be exercised anytime before maturity. No closed-form formula exists! Must solve the free boundary problem: \\[\\max\\left(\\frac{\\partial V}{\\partial t} + \\frac{1}{2}\\sigma^2 S^2\\frac{\\partial^2 V}{\\partial S^2} + rS\\frac{\\partial V}{\\partial S} - rV, \\, g(S) - V\\right) = 0\\] where \\(g(S)\\) is the exercise payoff. 6.6.1 Early Exercise Premium \\[V_{American} = V_{European} + \\text{Early Exercise Premium}\\] For calls on non-dividend paying stocks: Early exercise premium = 0 (never optimal to exercise early). For puts: Early exercise can be optimal (when deep in-the-money). 6.7 Extensions 6.7.1 Dividends If stock pays continuous dividend yield \\(q\\): \\[C = Se^{-q(T-t)}\\Phi(d_1) - Ke^{-r(T-t)}\\Phi(d_2)\\] where \\(d_1, d_2\\) are modified to include \\(q\\). 6.7.2 Exotic Options Digital options: Pay $1 or $0 Barrier options: Activated/deactivated if stock crosses barrier Asian options: Payoff depends on average price Lookback options: Payoff depends on maximum/minimum Each requires specialized techniques! 6.8 Limitations of Black-Scholes Constant volatility: Real volatility varies and is stochastic No jumps: Stocks can gap (earnings, news) Log-normal distribution: Real returns have fat tails Continuous trading: Transaction costs exist Known parameters: Volatility and drift are unknown Despite limitations, Black-Scholes is: - A benchmark for pricing and hedging - The foundation for more sophisticated models - Still widely used (with adjustments) The framework is more important than the formula itself! "],["jump-diffusion-models.html", "Chapter 7 Jump-Diffusion Models 7.1 Why Jumps Matter 7.2 The Poisson Process 7.3 Compound Poisson Process 7.4 Merton’s Jump-Diffusion Model 7.5 Itô’s Lemma with Jumps 7.6 Risk-Neutral Pricing with Jumps 7.7 Merton’s Option Pricing Formula 7.8 The PIDE 7.9 Market Implications 7.10 Extensions 7.11 Summary", " Chapter 7 Jump-Diffusion Models 7.1 Why Jumps Matter Brownian motion assumes continuous price paths. But real markets exhibit: Earnings announcements: Stock gaps 10%+ overnight Central bank decisions: FX rates jump instantly Black swan events: Market crashes, flash crashes Fat tails: Extreme returns occur more often than log-normal predicts Purely diffusive models systematically underprice out-of-the-money options. 7.2 The Poisson Process Before jumps, we need to count random events. Definition: \\(N(t)\\) is a Poisson process with intensity \\(\\lambda\\) if: \\(N(0) = 0\\) Independent increments \\(N(t) - N(s) \\sim \\text{Poisson}(\\lambda(t-s))\\) for \\(t &gt; s\\) Paths are step functions (jumps of size 1) Properties: - \\(E[N(t)] = \\lambda t\\) (average \\(\\lambda\\) events per unit time) - \\(\\text{Var}(N(t)) = \\lambda t\\) - \\(P(N(t) = k) = \\frac{(\\lambda t)^k e^{-\\lambda t}}{k!}\\) - Waiting times between events: exponential with rate \\(\\lambda\\) Differential notation: \\[dN(t) = \\begin{cases} 1 &amp; \\text{with probability } \\lambda \\, dt \\\\ 0 &amp; \\text{with probability } 1 - \\lambda \\, dt \\end{cases}\\] Key property: \\((dN)^2 = dN\\) (since \\(dN \\in \\{0,1\\}\\) and \\(1^2 = 1\\)). 7.3 Compound Poisson Process Add random jump sizes: \\[J(t) = \\sum_{i=1}^{N(t)} Y_i\\] where \\(Y_i\\) are i.i.d. random jumps (often \\(Y_i \\sim N(\\mu_J, \\sigma_J^2)\\)). In differential form: \\[dJ(t) = Y \\, dN(t)\\] where \\(Y\\) is drawn when a jump occurs. 7.4 Merton’s Jump-Diffusion Model Combine Brownian motion with compound Poisson jumps: \\[\\boxed{\\frac{dS}{S} = \\mu \\, dt + \\sigma \\, dB + (e^Y - 1) \\, dN}\\] Components: - \\(\\mu \\, dt\\): Deterministic drift - \\(\\sigma \\, dB\\): Continuous diffusion (Brownian) - \\((e^Y - 1) \\, dN\\): Discontinuous jumps Jump structure: - Jumps arrive with intensity \\(\\lambda\\) - When jump occurs: \\(S \\to S \\cdot e^Y\\) (multiplicative) - Typically \\(Y \\sim N(\\mu_J, \\sigma_J^2)\\) (log-normal jumps) 7.4.1 Why \\(e^Y - 1\\)? If \\(Y = \\log(1 + k)\\) where \\(k\\) is the percentage jump: \\[S_{\\text{after}} = S_{\\text{before}} \\cdot e^Y = S_{\\text{before}} \\cdot (1 + k)\\] So a 10% down move corresponds to \\(Y = \\log(0.9) \\approx -0.105\\). 7.5 Itô’s Lemma with Jumps For a function \\(f(S)\\) where \\(S\\) follows jump-diffusion, Itô’s lemma becomes: \\[df = \\frac{\\partial f}{\\partial S}dS + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial S^2}(dS)^2 + [f(Se^Y) - f(S) - \\frac{\\partial f}{\\partial S}S(e^Y - 1)]\\,dN\\] The last term is the jump correction: actual jump minus first-order Taylor approximation. Multiplication rules: - \\(dB \\cdot dN = 0\\) (jumps and diffusion independent) - \\(dt \\cdot dN = 0\\) - \\(dN \\cdot dN = dN\\) (only one jump at a time) 7.5.1 Example: Log Price Apply to \\(f(S) = \\log S\\): \\[d(\\log S) = \\left(\\mu - \\frac{\\sigma^2}{2}\\right)dt + \\sigma \\, dB + Y \\, dN\\] Integrating: \\[\\log S(t) = \\log S(0) + \\left(\\mu - \\frac{\\sigma^2}{2}\\right)t + \\sigma B(t) + \\sum_{i=1}^{N(t)} Y_i\\] Log price = drift + Brownian + sum of jumps. Clean decomposition! 7.6 Risk-Neutral Pricing with Jumps Under \\(\\mathbb{Q}\\), discounted price must be martingale: \\[\\frac{dS}{S} = (r - \\lambda \\kappa) \\, dt + \\sigma \\, d\\tilde{B} + (e^Y - 1) \\, d\\tilde{N}\\] where \\(\\kappa = E^{\\mathbb{Q}}[e^Y - 1]\\) is the expected jump size. The drift adjustment \\(-\\lambda \\kappa\\) compensates for jumps to maintain martingale property. If jumps are log-normal: \\(Y \\sim N(\\mu_J, \\sigma_J^2)\\), then: \\[\\kappa = e^{\\mu_J + \\sigma_J^2/2} - 1\\] 7.6.1 The Critical Insight With jumps, you cannot perfectly hedge! Jump risk cannot be eliminated through continuous rebalancing. This fundamentally changes the pricing problem. 7.7 Merton’s Option Pricing Formula For a European call: \\[\\boxed{C(S, t) = \\sum_{n=0}^{\\infty} \\frac{e^{-\\lambda&#39;(T-t)}[\\lambda&#39;(T-t)]^n}{n!} \\text{BS}(S, K, r_n, \\sigma_n, T-t)}\\] where: - \\(\\lambda&#39; = \\lambda(1 + \\kappa)\\) is adjusted intensity - \\(\\text{BS}(\\cdot)\\) is Black-Scholes formula with modified parameters: - \\(r_n = r - \\lambda\\kappa + \\frac{n\\log(1+\\kappa)}{T-t}\\) - \\(\\sigma_n^2 = \\sigma^2 + \\frac{n\\sigma_J^2}{T-t}\\) Interpretation: Weighted average of Black-Scholes prices, each term corresponding to exactly \\(n\\) jumps before maturity. 7.8 The PIDE For general derivatives, the pricing equation becomes a partial integro-differential equation: \\[\\frac{\\partial V}{\\partial t} + (r - \\lambda\\kappa)S\\frac{\\partial V}{\\partial S} + \\frac{1}{2}\\sigma^2 S^2\\frac{\\partial^2 V}{\\partial S^2}\\] \\[+ \\lambda\\int_{-\\infty}^{\\infty}[V(t, Se^y) - V(t,S)]f(y)\\,dy = rV\\] The integral accounts for all possible jump outcomes, weighted by their probability density \\(f(y)\\). Much harder to solve than Black-Scholes PDE! Typically requires numerical methods: - Monte Carlo simulation - Fourier methods (FFT) - Finite difference on jump-diffusion grid 7.9 Market Implications 7.9.1 Volatility Smile Jump models naturally produce volatility smiles: - Out-of-the-money puts protect against downward jumps → higher implied vol - Near-the-money options less affected → lower implied vol - Creates the characteristic “smirk” in equity markets 7.9.2 Greeks Greeks behave differently with jumps: - Delta no longer perfect hedge ratio - Vega has two components: diffusion vol + jump vol - New Greeks: sensitivity to jump intensity (\\(\\partial V/\\partial \\lambda\\)), jump size - Jump risk premium: additional risk that can’t be hedged 7.9.3 Calibration More parameters to fit: - Brownian: \\(\\mu\\), \\(\\sigma\\) - Jumps: \\(\\lambda\\), \\(\\mu_J\\), \\(\\sigma_J\\) Pros: More flexible, fits market data better Cons: Harder to calibrate, identifiability issues 7.10 Extensions 7.10.1 Double exponential jumps Use asymmetric exponential distributions for up/down jumps: \\[f(y) = \\begin{cases} p \\eta_u e^{-\\eta_u y} &amp; y \\geq 0 \\\\ (1-p) \\eta_d e^{\\eta_d y} &amp; y &lt; 0 \\end{cases}\\] Allows different behavior for positive and negative jumps (market asymmetry). 7.10.2 Stochastic intensity Let \\(\\lambda\\) itself be random: \\[d\\lambda = a(\\lambda) \\, dt + b(\\lambda) \\, dW\\] Models “volatility clustering” of jumps (crises come in waves). 7.10.3 Jump-to-default Special case: when jump occurs, stock goes to zero (bankruptcy): \\[P(\\text{jump to default in } dt) = h \\, dt\\] Used in credit risk models. 7.11 Summary Jump-diffusion models capture: - Discrete shocks in addition to continuous uncertainty - Fat tails and skewness in return distributions - Incomplete markets and non-hedgeable risk - More realistic market dynamics They’re the bridge between Black-Scholes and more sophisticated Lévy process models. "],["lévy-processes.html", "Chapter 8 Lévy Processes 8.1 The Ultimate Generalization 8.2 Examples We Know 8.3 The Lévy-Khintchine Representation 8.4 Types of Jump Behavior 8.5 Popular Lévy Processes in Finance 8.6 Why Lévy Processes Matter for Finance 8.7 Pricing with Lévy Processes 8.8 The Lévy Landscape 8.9 Subordination 8.10 Limitations and Extensions 8.11 The Full Circle 8.12 Further Directions", " Chapter 8 Lévy Processes 8.1 The Ultimate Generalization Lévy processes unify everything we’ve learned: random walks, Brownian motion, Poisson processes, and jump-diffusions are all special cases. Definition: A process \\(L(t)\\) is a Lévy process if: \\(L(0) = 0\\) Independent increments: \\(L(t) - L(s)\\) independent of past for \\(t &gt; s\\) Stationary increments: \\(L(t) - L(s) \\sim L(t-s)\\) (distribution depends only on time difference) Stochastic continuity: \\(\\lim_{h \\to 0} P(|L(t+h) - L(t)| &gt; \\epsilon) = 0\\) for all \\(\\epsilon &gt; 0\\) Càdlàg paths: Right-continuous with left limits (allows jumps) Lévy processes are the natural class of “time-homogeneous processes with independent increments.” 8.2 Examples We Know All of these are Lévy processes: Brownian motion: Continuous paths, no jumps Poisson process: Jumps of size 1 Compound Poisson: Random-sized jumps at Poisson times Merton jump-diffusion: Brownian + Compound Poisson Stable processes: Including Cauchy process Variance Gamma: Time-changed Brownian motion Normal Inverse Gaussian (NIG): Popular in finance 8.3 The Lévy-Khintchine Representation Here’s the magic: Every Lévy process decomposes into three independent parts: \\[\\boxed{L(t) = \\gamma t + \\sigma B(t) + J(t)}\\] where: \\(\\gamma t\\): Linear drift (deterministic) \\(\\sigma B(t)\\): Brownian component (continuous random) \\(J(t)\\): Pure jump component (discontinuous) The jump component is characterized by a Lévy measure \\(\\nu(dy)\\) which tells us: - How often jumps of size around \\(y\\) occur - Can have infinitely many jumps in finite time! 8.3.1 The Lévy-Khintchine Formula The characteristic function (Fourier transform) is: \\[E[e^{i\\theta L(t)}] = \\exp\\left[t\\psi(\\theta)\\right]\\] where the Lévy symbol is: \\[\\psi(\\theta) = i\\theta\\gamma - \\frac{1}{2}\\sigma^2\\theta^2 + \\int_{-\\infty}^{\\infty}(e^{i\\theta y} - 1 - i\\theta y\\mathbb{1}_{|y|&lt;1})\\nu(dy)\\] The Lévy triplet \\((\\gamma, \\sigma^2, \\nu)\\) completely characterizes any Lévy process! 8.4 Types of Jump Behavior The Lévy measure \\(\\nu\\) determines the jump structure. 8.4.1 Finite Activity \\[\\int \\nu(dy) &lt; \\infty\\] Finitely many jumps in any finite interval. Example: Compound Poisson. 8.4.2 Infinite Activity \\[\\int \\nu(dy) = \\infty\\] Infinitely many jumps, but most are tiny. Examples: Variance Gamma, NIG. Intuition: Like continuous process, but with “microstructure” of tiny jumps. 8.4.3 Finite Variation \\[\\int |y| \\nu(dy) &lt; \\infty\\] Total jump variation is finite. Path has bounded variation. 8.4.4 Infinite Variation \\[\\int |y| \\nu(dy) = \\infty\\] Accumulation of many small jumps creates unbounded variation, like Brownian motion. 8.5 Popular Lévy Processes in Finance 8.5.1 Variance Gamma (VG) Infinite activity, finite variation Time-changed Brownian motion: \\(VG(t) = B(\\Gamma(t))\\) where \\(\\Gamma\\) is a gamma process Lévy density: \\(\\nu(dy) = \\frac{C}{|y|}e^{-\\lambda|y|}dy\\) Three parameters to fit: shape volatility smile Computationally tractable (FFT methods) Use: Equity options, capturing skewness and kurtosis. 8.5.2 Normal Inverse Gaussian (NIG) Infinite activity, infinite variation Hyperbolic distribution for log-returns Lévy density involves modified Bessel function Four parameters: very flexible Good fit to empirical return distributions Use: General modeling when need flexible, fat-tailed distribution. 8.5.3 CGMY (Carr-Geman-Madan-Yor) Generalizes many models Lévy density: \\(\\nu(dy) = C \\frac{e^{-G|y|}}{|y|^{1+Y}}\\) for \\(y &lt; 0\\), similar for \\(y &gt; 0\\) Parameter \\(Y\\) controls fine vs coarse structure: \\(Y &lt; 0\\): Finite activity \\(0 &lt; Y &lt; 1\\): Infinite activity, finite variation \\(1 &lt; Y &lt; 2\\): Infinite activity, infinite variation \\(Y = 0\\): Reduces to Variance Gamma Use: Ultimate flexibility in modeling jump behavior. 8.5.4 Tempered Stable Processes Compromise between stable (heavy tails) and exponential (light tails) Lévy density has power-law behavior near 0, exponential decay at infinity Captures both frequent small jumps and rare large jumps Use: Modeling extreme events while maintaining tractability. 8.6 Why Lévy Processes Matter for Finance 8.6.1 Empirical Fit Real asset return distributions exhibit: Fat tails: \\(P(|R| &gt; x)\\) decays slower than Gaussian Skewness: Asymmetric (negative skew for equities) Excess kurtosis: More peaked at center, fatter tails Lévy processes can match all three! 8.6.2 Infinite Divisibility Any time period can be subdivided arbitrarily: \\[L(t) \\stackrel{d}{=} L(t/n) + L(t/n) + \\cdots + L(t/n)\\] This mirrors the multiplicativity of returns in finance. 8.6.3 Tractability Despite complexity: Semi-closed form option prices via Fourier methods Fast computation using FFT Analytical Greeks (sometimes) Efficient simulation algorithms The balance of realism and tractability makes them practical. 8.7 Pricing with Lévy Processes For stock following: \\[\\frac{dS}{S} = r \\, dt + dL(t)\\] where \\(L\\) is a Lévy process under \\(\\mathbb{Q}\\), the option price satisfies: \\[\\frac{\\partial V}{\\partial t} + (r - \\psi(-i))S\\frac{\\partial V}{\\partial S} + \\frac{1}{2}\\sigma^2 S^2\\frac{\\partial^2 V}{\\partial S^2}\\] \\[+ \\int_{-\\infty}^{\\infty}\\left[V(t, Se^y) - V(t,S) - S(e^y - 1)\\frac{\\partial V}{\\partial S}\\right]\\nu(dy) = rV\\] This PIDE is generally solved using: Fourier methods: Transform to frequency domain, solve algebraically, transform back Monte Carlo: Simulate Lévy process paths, average payoffs Finite differences: Discretize the PIDE on a grid 8.7.1 Characteristic Function Method For European options, use: \\[C(K) = \\frac{e^{-rT}}{2\\pi}\\int_{-\\infty}^{\\infty} e^{-i\\omega \\log K} \\hat{g}(\\omega) \\, d\\omega\\] where \\(\\hat{g}\\) is the Fourier transform of the payoff function, computed using the characteristic function of \\(L(T)\\). Fast Fourier Transform (FFT) makes this efficient for computing prices across many strikes simultaneously. 8.8 The Lévy Landscape Lévy Processes | +----------------+----------------+ | | Continuous Jumps (Brownian) | +---------------+---------------+ | | Finite activity Infinite activity (Compound Poisson) | +---------------+---------------+ | | Finite variation Infinite variation (VG, some CGMY) (NIG, some CGMY) 8.9 Subordination Many Lévy processes arise through subordination: time-changing one process by another. If \\(X(t)\\) is a Lévy process and \\(T(t)\\) is an increasing Lévy process (subordinator), then: \\[Y(t) = X(T(t))\\] is also a Lévy process. Examples: - Variance Gamma: \\(VG(t) = B(T(t))\\) where \\(T\\) is gamma - NIG: Time-change Brownian motion by inverse Gaussian This gives an intuitive way to build flexible processes. 8.10 Limitations and Extensions 8.10.1 What Lévy processes cannot capture Stochastic volatility: Volatility itself random and path-dependent Volatility clustering: High volatility periods persist Long-range dependence: Correlations decay slowly 8.10.2 Modern extensions Lévy-driven SDEs: \\(dX = \\mu(X) dt + \\sigma(X) dL\\) Time-changed Lévy processes: Random time changes Lévy copulas: Multivariate Lévy dependence Fractional Lévy processes: Long memory Rough volatility: Paths rougher than Brownian These are active research areas combining stochastic calculus with other mathematical tools. 8.11 The Full Circle We started with: Random walks → (scaling) → Brownian motion → (SDEs) → Jump-diffusion → (generalization) → Lévy processes Each step added: - Brownian: Continuous randomness - SDEs: State-dependent dynamics - Jumps: Discontinuous shocks - Lévy: Full generality of time-homogeneous randomness All unified by: - PDEs/PIDEs (analytical methods) - Martingales (probabilistic methods) - Fourier methods (computational finance) - Itô calculus (the foundation) This framework underlies modern quantitative finance, connecting pure mathematics, probability theory, and real-world markets in a beautiful and practical way. 8.12 Further Directions Having mastered stochastic calculus and Lévy processes, you can explore: Stochastic volatility models (Heston, SABR) Local volatility and implied volatility surfaces Rough volatility and fractional Brownian motion Term structure models (interest rates, credit) Optimal stopping and American options Stochastic control and dynamic programming Filtering theory and partial information Malliavin calculus and Monte Carlo methods The journey never ends - but you now have the foundation to explore any of these advanced topics. Congratulations! "],["linear-algebra.html", "A Essential Linear Algebra Why Geometry Matters A.1 Vectors and Linear Transformations A.2 Eigendecomposition: Finding the Fixed Directions A.3 Singular Value Decomposition A.4 Implications: Principal Component Analysis Summary", " A Essential Linear Algebra “The purpose of computing is insight, not numbers.” — Richard Hamming This appendix provides the geometric intuition behind linear algebra that underlies much of stochastic calculus and its applications. We emphasize what linear transformations do rather than computational recipes. Why Geometry Matters Linear algebra is often taught as a collection of matrix manipulations. But matrices are geometric transformations, and understanding this perspective unlocks deep insights: Covariance matrices describe the shape of probability distributions Eigenvalues reveal the principal directions of variation The singular value decomposition shows that every linear map is fundamentally simple The payoff for finance: principal component analysis, factor models, and risk decomposition all become geometrically transparent. A.1 Vectors and Linear Transformations Vectors as Arrows A vector \\(\\mathbf{v} \\in \\mathbb{R}^n\\) is an arrow from the origin. In \\(\\mathbb{R}^2\\): \\[\\mathbf{v} = \\begin{pmatrix} v_1 \\\\ v_2 \\end{pmatrix}\\] represents a displacement of \\(v_1\\) units horizontally and \\(v_2\\) units vertically. Matrices as Transformations A matrix \\(A\\) is not just a grid of numbers—it’s an instruction for transforming space. When we compute \\(A\\mathbf{v}\\), we’re asking: “Where does the arrow \\(\\mathbf{v}\\) land after applying transformation \\(A\\)?” The column perspective: The columns of \\(A\\) tell you where the standard basis vectors land. If \\[A = \\begin{pmatrix} a &amp; b \\\\ c &amp; d \\end{pmatrix}\\] then: The first column \\((a, c)^T\\) is where \\(\\mathbf{e}_1 = (1, 0)^T\\) goes The second column \\((b, d)^T\\) is where \\(\\mathbf{e}_2 = (0, 1)^T\\) goes Every other vector, being a linear combination of \\(\\mathbf{e}_1\\) and \\(\\mathbf{e}_2\\), gets carried along accordingly. What Can Linear Transformations Do? Linear transformations can: Rotate (turn space around the origin) Scale (stretch or compress along axes) Shear (slide layers past each other) Reflect (flip across a line or plane) Project (flatten onto a lower-dimensional subspace) What they cannot do: translate (shift the origin), bend, or curve space. A.2 Eigendecomposition: Finding the Fixed Directions The Central Question Given a transformation \\(A\\), are there any directions that remain unchanged—vectors that get scaled but not rotated? Definition. A nonzero vector \\(\\mathbf{v}\\) is an eigenvector of \\(A\\) with eigenvalue \\(\\lambda\\) if: \\[A\\mathbf{v} = \\lambda \\mathbf{v}\\] The transformation \\(A\\) acts on \\(\\mathbf{v}\\) by simply stretching (or compressing, or flipping) it by factor \\(\\lambda\\). Eigenvectors as Fixed Directions This is the geometric essence: eigenvectors are the directions that “survive” the transformation unchanged in orientation. Consider what happens to a general vector under repeated application of \\(A\\): Directions aligned with eigenvectors corresponding to \\(|\\lambda| &gt; 1\\) get amplified Directions aligned with eigenvectors corresponding to \\(|\\lambda| &lt; 1\\) get suppressed The eigenvector with the largest \\(|\\lambda|\\) eventually dominates This explains why: Dominant eigenvectors emerge in iterative processes Principal components capture the most important directions of variation Markov chains converge to stationary distributions (the eigenvector with \\(\\lambda = 1\\)) The Eigendecomposition For a matrix \\(A\\) with \\(n\\) linearly independent eigenvectors, we can write: \\[A = V \\Lambda V^{-1}\\] where: \\(V\\) is the matrix whose columns are eigenvectors \\(\\Lambda\\) is diagonal with eigenvalues on the diagonal Geometric interpretation: To apply \\(A\\): Express the input in the eigenvector basis (\\(V^{-1}\\)) Scale each component by its eigenvalue (\\(\\Lambda\\)) Convert back to the standard basis (\\(V\\)) Special Case: Symmetric Matrices When \\(A = A^T\\) (symmetric), something beautiful happens: All eigenvalues are real Eigenvectors corresponding to different eigenvalues are orthogonal We can choose an orthonormal eigenvector basis The decomposition becomes: \\[A = Q \\Lambda Q^T\\] where \\(Q\\) is orthogonal (\\(Q^{-1} = Q^T\\)). This is the spectral decomposition. Why this matters: Covariance matrices are symmetric. Their eigenvectors define orthogonal axes of variation, and their eigenvalues measure variance along each axis. A.3 Singular Value Decomposition Beyond Square Matrices Eigendecomposition requires square matrices. But what about rectangular matrices—say, a \\(m \\times n\\) data matrix with \\(m\\) observations and \\(n\\) variables? The singular value decomposition (SVD) extends the geometric insight to any matrix. The SVD Theorem Theorem. Any \\(m \\times n\\) matrix \\(A\\) can be written as: \\[A = U \\Sigma V^T\\] where: \\(U\\) is \\(m \\times m\\) orthogonal (columns are left singular vectors) \\(\\Sigma\\) is \\(m \\times n\\) diagonal with non-negative singular values \\(\\sigma_1 \\geq \\sigma_2 \\geq \\cdots \\geq 0\\) \\(V\\) is \\(n \\times n\\) orthogonal (columns are right singular vectors) The Geometric Revelation The SVD reveals that every linear transformation is a rotation, followed by scaling, followed by another rotation: \\[A\\mathbf{x} = U \\Sigma V^T \\mathbf{x}\\] Reading right to left: \\(V^T\\): First rotation — Rotate the input space to align with the “natural axes” of the transformation \\(\\Sigma\\): Scaling — Scale along each axis by the singular values (and possibly embed into a different dimension) \\(U\\): Second rotation — Rotate the output space to the final orientation This is remarkable: no matter how complicated \\(A\\) appears, its action is fundamentally three simple operations. Connection to Eigendecomposition The SVD and eigendecomposition are intimately related: The columns of \\(V\\) are eigenvectors of \\(A^T A\\) The columns of \\(U\\) are eigenvectors of \\(A A^T\\) The singular values \\(\\sigma_i\\) are square roots of eigenvalues of \\(A^T A\\) (or \\(A A^T\\)) For symmetric positive semi-definite matrices: The SVD coincides with the eigendecomposition, and singular values equal eigenvalues. Geometric Interpretation of Singular Values Consider the unit sphere \\(\\{\\mathbf{x} : \\|\\mathbf{x}\\| = 1\\}\\). Under transformation \\(A\\): The sphere becomes an ellipsoid The semi-axes of the ellipsoid point in directions \\(U\\) The lengths of the semi-axes are the singular values \\(\\sigma_i\\) The largest singular value \\(\\sigma_1\\) is the maximum “stretch factor”—the operator norm of \\(A\\). Low-Rank Approximation A key property: if we keep only the \\(k\\) largest singular values, we get the best rank-\\(k\\) approximation to \\(A\\): \\[A_k = \\sum_{i=1}^{k} \\sigma_i \\mathbf{u}_i \\mathbf{v}_i^T\\] “Best” means minimizing the Frobenius norm of the error. This is the foundation of dimensionality reduction. A.4 Implications: Principal Component Analysis The Setup You have a data matrix \\(X\\) with \\(n\\) observations (rows) and \\(p\\) variables (columns), centered so each column has mean zero. The sample covariance matrix is: \\[S = \\frac{1}{n-1} X^T X\\] This symmetric matrix encodes how variables co-vary. The Geometric View The data points form a cloud in \\(p\\)-dimensional space. The covariance matrix \\(S\\) describes the shape of this cloud: Eigenvectors of \\(S\\) point along the principal axes of the ellipsoidal cloud Eigenvalues measure the variance (spread) along each axis Principal Components Definition. The principal components are the eigenvectors of the covariance matrix, ordered by decreasing eigenvalue. The first principal component (PC1) points in the direction of maximum variance PC2 is orthogonal to PC1 and captures the most remaining variance And so on… The SVD Connection We can bypass the covariance matrix entirely using the SVD of the centered data matrix: \\[X = U \\Sigma V^T\\] Then: The columns of \\(V\\) are the principal component directions The principal component scores are \\(U\\Sigma\\) (or equivalently, \\(XV\\)) The variance explained by the \\(i\\)-th component is \\(\\sigma_i^2 / (n-1)\\) Why PCA Matters for Finance Dimensionality reduction: Hundreds of asset returns can often be summarized by a handful of factors Factor discovery: The first few principal components of equity returns often correspond to interpretable factors (market, size, value…) Risk decomposition: Eigenvalues of the covariance matrix reveal how risk is distributed across independent directions Noise reduction: Discarding small eigenvalues (and their eigenvectors) filters out estimation noise A Caution PCA finds directions of maximum variance, not maximum importance. In finance: High variance might reflect noise, not signal The most predictive features may not be the most variable Covariance estimates are notoriously unstable Use PCA as a tool for exploration and compression, but interpret with care. Summary The geometric view of linear algebra reveals: Concept Geometric Meaning Matrix A transformation of space Eigenvector A direction that survives unchanged Eigenvalue The scaling factor along that direction Symmetric matrix Has orthogonal eigenvectors SVD Any transformation = rotate, scale, rotate Singular values Semi-axes of the transformed unit sphere PCA Find the axes of maximum spread This geometric intuition makes covariance matrices, factor models, and dimensionality reduction transparent—essential tools for working with multivariate stochastic processes. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
