[["index.html", "Stochastic Calculus from Scratch Preface What You’ll Learn Prerequisites About This Book", " Stochastic Calculus from Scratch Abhinav Anand 2026-01-07 Preface Welcome to Stochastic Calculus from Scratch! This book provides a comprehensive journey through random processes and their applications in financial mathematics. What You’ll Learn This book covers: Random walks and Brownian motion Itô’s lemma and stochastic integration Stochastic differential equations (SDEs) The Feynman-Kac connection between SDEs and PDEs Risk-neutral pricing and martingales Black-Scholes theory and the Greeks Jump-diffusion models Lévy processes Prerequisites Readers should be comfortable with: Calculus (derivatives, integrals) Basic probability theory (random variables, expectations, variance) Linear algebra fundamentals About This Book This book grew out of an interactive teaching session focused on building intuition for stochastic calculus from first principles. The emphasis is on understanding why things work, not just what the formulas are. Each chapter builds on previous concepts, so I recommend reading sequentially, especially if you’re new to the subject. Let’s begin our journey into the beautiful world of stochastic calculus! "],["random-walks-and-brownian-motion.html", "Chapter 1 Random Walks and Brownian Motion 1.1 Simple Random Walk 1.2 Scaling to Continuous Time 1.3 Brownian Motion Emerges 1.4 Properties of Brownian Motion 1.5 Historical Note", " Chapter 1 Random Walks and Brownian Motion 1.1 Simple Random Walk Imagine flipping a fair coin repeatedly. After each flip, you take a step: heads = +1, tails = -1. Your position after \\(n\\) steps is: \\[S_n = X_1 + X_2 + \\cdots + X_n\\] where each \\(X_i \\in \\{-1, +1\\}\\) with equal probability. This is a simple random walk. 1.1.1 Key Properties The random walk has several important characteristics: Expected position: \\(E[S_n] = 0\\) (you expect to end where you started) Variance: \\(\\text{Var}(S_n) = n\\) (the variance grows linearly with time) Asymptotic behavior: \\(S_n \\sim \\sqrt{n} \\cdot N(0,1)\\) approximately, by the Central Limit Theorem The last property tells us that even though each individual step is discrete, the rescaled position becomes approximately normal for large \\(n\\). 1.2 Scaling to Continuous Time Now here’s the beautiful leap: Let’s speed up time and shrink the steps. Divide time into tiny intervals of length \\(\\Delta t\\), and let each step have size \\(\\Delta x\\). After time \\(t\\), we’ve taken \\(n = t/\\Delta t\\) steps. If we want the limiting process to have the same “spreading” behavior, we need \\(\\text{Var}(S_n) \\sim t\\). Since variance adds, and we take \\(n = t/\\Delta t\\) steps: \\[n \\cdot (\\Delta x)^2 = \\frac{t}{\\Delta t} \\cdot (\\Delta x)^2 \\sim t\\] This means we need: \\[(\\Delta x)^2 \\sim \\Delta t\\] or equivalently: \\[\\Delta x \\sim \\sqrt{\\Delta t}\\] This is the crucial scaling! Steps shrink like the square root of the time interval, not proportionally to time itself. This counterintuitive scaling is at the heart of stochastic calculus. 1.3 Brownian Motion Emerges Taking the limit as \\(\\Delta t \\to 0\\), we get a continuous random process \\(B(t)\\) called Brownian motion (or the Wiener process). 1.3.1 Formal Definition A stochastic process \\(B(t)\\) is Brownian motion if it satisfies: Initial condition: \\(B(0) = 0\\) Independent increments: For any \\(t &gt; s\\), the increment \\(B(t) - B(s)\\) is independent of all information up to time \\(s\\) Normal increments: \\(B(t) - B(s) \\sim N(0, t-s)\\) for \\(t &gt; s\\) Continuous paths: \\(B(t)\\) has continuous paths (no jumps) The third property captures that crucial \\(\\Delta x \\sim \\sqrt{\\Delta t}\\) scaling we derived above. 1.3.2 A Shocking Fact Despite being continuous everywhere, Brownian motion is differentiable nowhere. The path is infinitely jagged at every scale. To see why, consider the “derivative”: \\[\\frac{B(t + \\Delta t) - B(t)}{\\Delta t} \\sim \\frac{N(0, \\Delta t)}{\\Delta t} \\sim \\frac{\\sqrt{\\Delta t}}{\\Delta t} = \\frac{1}{\\sqrt{\\Delta t}} \\to \\infty\\] as \\(\\Delta t \\to 0\\). The “instantaneous velocity” is infinite! This is why we need new mathematical tools - traditional calculus breaks down for such rough functions. 1.4 Properties of Brownian Motion 1.4.1 Quadratic Variation For any partition \\(0 = t_0 &lt; t_1 &lt; \\cdots &lt; t_n = t\\), consider: \\[\\sum_{i=0}^{n-1} [B(t_{i+1}) - B(t_i)]^2\\] As the partition gets finer, this sum converges to \\(t\\) (not zero, as it would for smooth functions!). We write: \\[[B, B](t) = t\\] This is called the quadratic variation of Brownian motion. 1.4.2 Markov Property Brownian motion is a Markov process: The future is independent of the past given the present. Formally: \\[P(B(t) \\in A \\mid B(s), s \\leq t_0) = P(B(t) \\in A \\mid B(t_0))\\] for \\(t &gt; t_0\\). 1.4.3 Martingale Property Brownian motion is a martingale: The best prediction of future position is the current position: \\[E[B(t) \\mid \\mathcal{F}_s] = B(s)\\] for all \\(t \\geq s\\), where \\(\\mathcal{F}_s\\) represents all information up to time \\(s\\). 1.4.4 Scaling Properties Brownian motion has interesting scaling invariance: Time scaling: If \\(B(t)\\) is Brownian motion, so is \\(\\frac{1}{\\sqrt{c}} B(ct)\\) for any \\(c &gt; 0\\) Reflection: \\(-B(t)\\) is also Brownian motion Time reversal: The process \\(t B(1/t)\\) for \\(t &gt; 0\\) is Brownian motion These symmetries make Brownian motion mathematically elegant and practically useful. 1.5 Historical Note Brownian motion is named after botanist Robert Brown, who in 1827 observed the erratic movement of pollen grains suspended in water. However, the mathematical theory was developed much later: 1900: Louis Bachelier used it to model stock prices (before Einstein!) 1905: Albert Einstein explained the physical phenomenon 1923: Norbert Wiener gave the first rigorous mathematical construction 1944: Kiyoshi Itô developed the calculus of Brownian motion This mathematical object bridges physics, biology, finance, and pure mathematics - a testament to its fundamental importance. "],["itô-integral-and-itôs-lemma.html", "Chapter 2 Itô Integral and Itô’s Lemma 2.1 The Challenge of Stochastic Integration 2.2 The Itô Integral 2.3 A Crucial Example: \\(\\int_0^t B(s) \\, dB(s)\\) 2.4 Quadratic Variation and the Formal Rule \\((dB)^2 = dt\\) 2.5 Itô’s Lemma: The Fundamental Theorem 2.6 Verification: Recovering Our Earlier Result 2.7 Example: The Exponential 2.8 General Itô’s Lemma 2.9 Why Itô’s Choice?", " Chapter 2 Itô Integral and Itô’s Lemma 2.1 The Challenge of Stochastic Integration In regular calculus, we integrate smooth functions: \\[\\int_0^t f(s) \\, ds = \\lim_{\\Delta s \\to 0} \\sum_{i} f(s_i) \\Delta s\\] For smooth functions \\(f\\), it doesn’t matter whether we evaluate at the left endpoint, right endpoint, or midpoint of each interval - we get the same answer in the limit. But what about: \\[\\int_0^t f(s) \\, dB(s) \\quad ?\\] This means integrating \\(f\\) with respect to Brownian motion. Instead of accumulating tiny areas \\(f(s_i) \\Delta s\\), we’re accumulating random contributions \\(f(s_i) \\Delta B_i\\) where \\(\\Delta B_i = B(s_{i+1}) - B(s_i)\\). 2.1.1 The Problem Because Brownian motion is so rough (nowhere differentiable), the choice of evaluation point matters critically! Different choices give different answers, even in the limit. This isn’t just a technical nuisance - it reflects a fundamental ambiguity about how to define integration with respect to a rough, random path. 2.2 The Itô Integral Kiyoshi Itô made a choice that turned out to be mathematically natural and practically useful: always evaluate at the left endpoint. 2.2.1 Definition The Itô integral is defined as: \\[\\int_0^t f(s) \\, dB(s) = \\lim_{n \\to \\infty} \\sum_{i=0}^{n-1} f(s_i) [B(s_{i+1}) - B(s_i)]\\] where \\(0 = s_0 &lt; s_1 &lt; \\cdots &lt; s_n = t\\) is a partition that gets progressively finer, and we use \\(f(s_i)\\) from the left of each interval. 2.2.2 Why the Left Endpoint? This choice makes \\(f(s_i)\\) independent of \\(\\Delta B_i = B(s_{i+1}) - B(s_i)\\), because \\(f(s_i)\\) depends only on information up to time \\(s_i\\), while \\(\\Delta B_i\\) is the future increment. This independence gives us beautiful properties: Martingale property: \\(\\int_0^t f(s) \\, dB(s)\\) is a martingale (under appropriate conditions on \\(f\\)) Zero expectation: \\(E\\left[\\int_0^t f(s) \\, dB(s)\\right] = 0\\) Isometry: \\(E\\left[\\left(\\int_0^t f(s) \\, dB(s)\\right)^2\\right] = E\\left[\\int_0^t f^2(s) \\, ds\\right]\\) The third property is called the Itô isometry and is fundamental for proving convergence. 2.3 A Crucial Example: \\(\\int_0^t B(s) \\, dB(s)\\) Let’s compute this integral using the definition. We want: \\[\\lim_{n \\to \\infty} \\sum_{i=0}^{n-1} B(s_i) [B(s_{i+1}) - B(s_i)]\\] Here’s a clever algebraic trick. Note that: \\[B^2(s_{i+1}) - B^2(s_i) = [B(s_{i+1}) - B(s_i)]^2 + 2B(s_i)[B(s_{i+1}) - B(s_i)]\\] Rearranging: \\[B(s_i)[B(s_{i+1}) - B(s_i)] = \\frac{1}{2}[B^2(s_{i+1}) - B^2(s_i)] - \\frac{1}{2}[B(s_{i+1}) - B(s_i)]^2\\] Summing over all intervals: \\[\\sum_{i=0}^{n-1} B(s_i) \\Delta B_i = \\frac{1}{2}[B^2(t) - B^2(0)] - \\frac{1}{2}\\sum_{i=0}^{n-1} (\\Delta B_i)^2\\] The first term telescopes to give \\(\\frac{1}{2}B^2(t)\\). But what about that second sum? 2.3.1 The Quadratic Variation Miracle Each \\((\\Delta B_i)^2\\) has expected value \\(E[(\\Delta B_i)^2] = s_{i+1} - s_i = \\Delta t_i\\). As the partition gets finer, by the law of large numbers: \\[\\sum_{i=0}^{n-1} (\\Delta B_i)^2 \\to t\\] This is the quadratic variation we mentioned earlier. Remarkably, it converges to the deterministic value \\(t\\)! Therefore: \\[\\boxed{\\int_0^t B(s) \\, dB(s) = \\frac{1}{2}B^2(t) - \\frac{1}{2}t}\\] 2.3.2 The Shock In regular calculus, \\(\\int_0^t x \\, dx = \\frac{1}{2}x^2\\). But here we get an extra \\(-\\frac{t}{2}\\) term! This correction term is the signature of stochastic calculus - it comes from the non-zero quadratic variation of Brownian motion. 2.4 Quadratic Variation and the Formal Rule \\((dB)^2 = dt\\) The key insight is: \\[\\sum_{i=0}^{n-1} (\\Delta B_i)^2 \\to t \\quad \\text{as } n \\to \\infty\\] In differential notation, we write this as the formal rule: \\[(dB)^2 = dt\\] This is not literally true (both sides are zero!), but it’s a mnemonic for the limiting behavior. 2.4.1 Multiplication Rules From \\((dB)^2 = dt\\), we can derive multiplication rules for stochastic differentials: Term Value Reason \\(dt \\cdot dt\\) \\(0\\) Second order in deterministic time \\(dt \\cdot dB\\) \\(0\\) Deterministic times random of order \\(\\sqrt{dt}\\) \\(dB \\cdot dB\\) \\(dt\\) Quadratic variation! These rules are essential for applying Itô’s lemma. 2.5 Itô’s Lemma: The Fundamental Theorem Now we come to the crown jewel - the chain rule for stochastic calculus. In regular calculus, if \\(x(t)\\) is differentiable and \\(f\\) is smooth: \\[\\frac{d}{dt}f(x(t)) = f&#39;(x(t)) \\cdot \\frac{dx}{dt}\\] Or in differential form: \\(df = f&#39;(x) \\, dx\\) Question: If \\(B(t)\\) is Brownian motion and \\(f\\) is smooth, what is \\(df(B(t))\\)? Naive guess: \\(df = f&#39;(B) \\, dB\\)? Wrong! 2.5.1 The Derivation Use Taylor expansion for small changes: \\[f(B(t + dt)) - f(B(t)) = f&#39;(B) \\cdot dB + \\frac{1}{2}f&#39;&#39;(B) \\cdot (dB)^2 + \\frac{1}{6}f&#39;&#39;&#39;(B) \\cdot (dB)^3 + \\cdots\\] In regular calculus, \\((dx)^2\\) and higher terms vanish as \\(dt \\to 0\\). But \\((dB)^2 = dt\\)! So the second-order term becomes: \\[\\frac{1}{2}f&#39;&#39;(B) \\cdot (dB)^2 = \\frac{1}{2}f&#39;&#39;(B) \\cdot dt\\] This term survives! The higher terms \\((dB)^3, (dB)^4, \\ldots\\) do vanish (they’re of order \\(dt^{3/2}, dt^2, \\ldots\\)). 2.5.2 Itô’s Lemma for \\(f(B(t))\\) \\[\\boxed{df(B) = f&#39;(B) \\, dB + \\frac{1}{2}f&#39;&#39;(B) \\, dt}\\] The extra \\(\\frac{1}{2}f&#39;&#39;(B) \\, dt\\) term is the Itô correction - the price we pay for the roughness of Brownian motion. 2.6 Verification: Recovering Our Earlier Result Let’s verify with \\(f(x) = x^2\\), so \\(f&#39;(x) = 2x\\) and \\(f&#39;&#39;(x) = 2\\). Itô’s lemma gives: \\[d(B^2) = 2B \\, dB + \\frac{1}{2} \\cdot 2 \\, dt = 2B \\, dB + dt\\] Integrating from 0 to \\(t\\): \\[B^2(t) - B^2(0) = 2\\int_0^t B(s) \\, dB(s) + t\\] Since \\(B(0) = 0\\): \\[B^2(t) = 2\\int_0^t B(s) \\, dB(s) + t\\] Therefore: \\[\\int_0^t B(s) \\, dB(s) = \\frac{1}{2}B^2(t) - \\frac{1}{2}t \\quad \\checkmark\\] Perfect match! 2.7 Example: The Exponential Take \\(f(x) = e^x\\), so \\(f&#39;(x) = f&#39;&#39;(x) = e^x\\). Itô’s lemma: \\[d(e^B) = e^B \\, dB + \\frac{1}{2}e^B \\, dt = e^B \\left(dB + \\frac{1}{2}dt\\right)\\] Integrating: \\[e^{B(t)} = 1 + \\int_0^t e^{B(s)} \\, dB(s) + \\frac{1}{2}\\int_0^t e^{B(s)} \\, ds\\] This is an integral equation for the exponential of Brownian motion. Taking expectations (the stochastic integral has zero mean): \\[E[e^{B(t)}] = 1 + \\frac{1}{2}\\int_0^t E[e^{B(s)}] \\, ds\\] Let \\(m(t) = E[e^{B(t)}]\\). Then \\(m&#39;(t) = \\frac{1}{2}m(t)\\) with \\(m(0) = 1\\). Solution: \\(E[e^{B(t)}] = e^{t/2}\\) You can verify this directly: since \\(B(t) \\sim N(0,t)\\), the moment generating function gives \\(E[e^{B(t)}] = e^{t/2}\\). ✓ 2.8 General Itô’s Lemma For a function \\(f(t, x)\\) of both time and space, and a process \\(X(t)\\): \\[\\boxed{df(t, X) = \\frac{\\partial f}{\\partial t}dt + \\frac{\\partial f}{\\partial x}dX + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}(dX)^2}\\] This is the form we’ll use most often in applications. 2.8.1 The Pattern To apply Itô’s lemma: Identify the function \\(f\\) and the stochastic process \\(X\\) Compute the partial derivatives: \\(\\frac{\\partial f}{\\partial t}\\), \\(\\frac{\\partial f}{\\partial x}\\), \\(\\frac{\\partial^2 f}{\\partial x^2}\\) Compute \\((dX)^2\\) using the multiplication rules Substitute everything into the formula This becomes second nature with practice! 2.9 Why Itô’s Choice? Other choices for the evaluation point lead to other stochastic calculi: Stratonovich integral: Uses the midpoint, gives different rules Backward integral: Uses the right endpoint Itô’s calculus won out because: Martingale property: Itô integrals are martingales Natural for finance: Fits the “no-anticipation” principle Connection to PDEs: Leads naturally to Feynman-Kac Computational advantage: Easier to simulate The Itô convention is now standard in probability, finance, and most applications. "],["stochastic-differential-equations.html", "Chapter 3 Stochastic Differential Equations 3.1 Introduction to SDEs 3.2 Geometric Brownian Motion 3.3 Ornstein-Uhlenbeck Process 3.4 General Strategy for Solving SDEs 3.5 Linear SDEs 3.6 Existence and Uniqueness 3.7 Strong vs. Weak Solutions 3.8 Multidimensional SDEs", " Chapter 3 Stochastic Differential Equations 3.1 Introduction to SDEs A stochastic differential equation (SDE) describes how a random process evolves over time, combining deterministic trends with random fluctuations. The general form is: \\[dX(t) = \\mu(t, X) \\, dt + \\sigma(t, X) \\, dB(t)\\] where: \\(\\mu(t, X)\\) is the drift coefficient - the deterministic trend \\(\\sigma(t, X)\\) is the diffusion coefficient (or volatility) - controls the random fluctuations \\(B(t)\\) is standard Brownian motion This differential equation is shorthand for the integral equation: \\[X(t) = X(0) + \\int_0^t \\mu(s, X(s)) \\, ds + \\int_0^t \\sigma(s, X(s)) \\, dB(s)\\] The first integral is ordinary (deterministic), the second is an Itô integral (random). 3.2 Geometric Brownian Motion The most famous SDE in finance models stock prices: \\[dS = \\mu S \\, dt + \\sigma S \\, dB\\] where \\(\\mu\\) and \\(\\sigma\\) are constants. 3.2.1 Interpretation Rewrite as: \\[\\frac{dS}{S} = \\mu \\, dt + \\sigma \\, dB\\] The return \\(dS/S\\) has two components: Deterministic drift: \\(\\mu \\, dt\\) per unit time Random shock: \\(\\sigma \\, dB\\) with volatility \\(\\sigma\\) This says returns (not prices!) have a constant drift and volatility. 3.2.2 Solving GBM We can’t just “integrate” the SDE directly. Instead, we use Itô’s lemma to find the right transformation! Strategy: Try \\(f(S) = \\log S\\). Then: - \\(f&#39;(S) = 1/S\\) - \\(f&#39;&#39;(S) = -1/S^2\\) From the SDE: \\(dS = \\mu S \\, dt + \\sigma S \\, dB\\) Therefore: \\((dS)^2 = (\\mu S \\, dt + \\sigma S \\, dB)^2 = \\sigma^2 S^2 (dB)^2 = \\sigma^2 S^2 \\, dt\\) (The \\(dt \\cdot dB\\) and \\((dt)^2\\) terms vanish.) By Itô’s lemma: \\[d(\\log S) = \\frac{1}{S} dS + \\frac{1}{2}\\left(-\\frac{1}{S^2}\\right)(dS)^2\\] \\[= \\frac{1}{S}(\\mu S \\, dt + \\sigma S \\, dB) - \\frac{1}{2} \\cdot \\frac{1}{S^2} \\cdot \\sigma^2 S^2 \\, dt\\] \\[= \\mu \\, dt + \\sigma \\, dB - \\frac{\\sigma^2}{2} \\, dt\\] \\[= \\left(\\mu - \\frac{\\sigma^2}{2}\\right) dt + \\sigma \\, dB\\] This is linear in \\(\\log S\\)! Integrating from 0 to \\(t\\): \\[\\log S(t) - \\log S(0) = \\left(\\mu - \\frac{\\sigma^2}{2}\\right)t + \\sigma B(t)\\] Exponentiating: \\[\\boxed{S(t) = S(0) \\exp\\left[\\left(\\mu - \\frac{\\sigma^2}{2}\\right)t + \\sigma B(t)\\right]}\\] 3.2.3 Key Observations Always positive: \\(S(t) &gt; 0\\) always (good for stock prices!) Log-normal: \\(\\log S(t)\\) is normally distributed Itô correction: The drift in the exponent is \\(\\mu - \\sigma^2/2\\), not \\(\\mu\\) Expected value: \\(E[S(t)] = S(0)e^{\\mu t}\\) (using the moment generating function) Median: \\(\\text{median}[S(t)] = S(0)e^{(\\mu - \\sigma^2/2)t}\\) The difference between \\(\\mu\\) and \\(\\mu - \\sigma^2/2\\) is sometimes called Jensen’s inequality correction or the convexity adjustment. 3.2.4 The Itô Correction Explained Why the \\(-\\sigma^2/2\\) term? The exponential function is convex. Because of volatility, \\(S(t)\\) spends more time in regions where the exponential curves upward. To maintain the correct expected drift rate, we need to adjust downward by \\(\\sigma^2/2\\). This is a general feature: non-linear transformations of stochastic processes pick up correction terms proportional to the second derivative (curvature). 3.3 Ornstein-Uhlenbeck Process This SDE models mean reversion - a tendency to return to a long-term average: \\[dX = -\\theta X \\, dt + \\sigma \\, dB\\] where \\(\\theta &gt; 0\\) is the mean reversion speed. 3.3.1 Interpretation When \\(X &gt; 0\\): drift is negative (pulled toward zero) When \\(X &lt; 0\\): drift is positive (pushed toward zero) Strength of pull proportional to distance from zero This models: - Interest rates (tend to revert to long-term average) - Commodity prices (mean reversion due to supply/demand) - Temperature (seasonal mean reversion) 3.3.2 Solving the OU Process Try the transformation \\(f(t, X) = e^{\\theta t} X\\). Partial derivatives: - \\(\\frac{\\partial f}{\\partial t} = \\theta e^{\\theta t} X\\) - \\(\\frac{\\partial f}{\\partial X} = e^{\\theta t}\\) - \\(\\frac{\\partial^2 f}{\\partial X^2} = 0\\) By Itô’s lemma: \\[d(e^{\\theta t} X) = \\theta e^{\\theta t} X \\, dt + e^{\\theta t} dX + 0\\] Substitute \\(dX = -\\theta X \\, dt + \\sigma \\, dB\\): \\[d(e^{\\theta t} X) = \\theta e^{\\theta t} X \\, dt + e^{\\theta t}(-\\theta X \\, dt + \\sigma \\, dB)\\] \\[= \\sigma e^{\\theta t} \\, dB\\] The drift terms cancel! Integrating: \\[e^{\\theta t} X(t) - X(0) = \\sigma \\int_0^t e^{\\theta s} \\, dB(s)\\] Therefore: \\[\\boxed{X(t) = X(0)e^{-\\theta t} + \\sigma \\int_0^t e^{-\\theta(t-s)} \\, dB(s)}\\] 3.3.3 Properties of the Solution Exponential decay: The initial condition \\(X(0)\\) decays as \\(e^{-\\theta t}\\) Half-life: Time to halve: \\(t_{1/2} = \\frac{\\log 2}{\\theta}\\) Gaussian: \\(X(t)\\) is normally distributed (it’s a linear combination of Brownian increments) Mean: \\(E[X(t)] = X(0)e^{-\\theta t} \\to 0\\) as \\(t \\to \\infty\\) Variance: \\(\\text{Var}(X(t)) = \\frac{\\sigma^2}{2\\theta}(1 - e^{-2\\theta t}) \\to \\frac{\\sigma^2}{2\\theta}\\) as \\(t \\to \\infty\\) The process reaches a stationary distribution \\(N(0, \\sigma^2/(2\\theta))\\) as \\(t \\to \\infty\\). 3.3.4 Generalization: OU with Mean \\(\\mu\\) The SDE: \\[dX = \\theta(\\mu - X) \\, dt + \\sigma \\, dB\\] reverts to a non-zero mean \\(\\mu\\). The solution is: \\[X(t) = \\mu + [X(0) - \\mu]e^{-\\theta t} + \\sigma \\int_0^t e^{-\\theta(t-s)} \\, dB(s)\\] Stationary distribution: \\(N(\\mu, \\sigma^2/(2\\theta))\\) 3.4 General Strategy for Solving SDEs Not all SDEs have closed-form solutions, but when they do, the strategy is: Guess a transformation \\(f(X)\\) or \\(f(t, X)\\) that might linearize or simplify things Apply Itô’s lemma to find \\(df\\) Hope that \\(df\\) is simpler (ideally linear or separable) Integrate and solve for \\(f\\) Transform back to find \\(X\\) Common tricks: - For multiplicative noise: try \\(\\log X\\) - For mean reversion: try \\(e^{\\theta t} X\\) - For time-dependent drift: try integrating factors - For Bessel processes: try \\(X^2\\) This is an art! Intuition comes with practice. 3.5 Linear SDEs SDEs of the form: \\[dX = [a(t) + b(t)X] \\, dt + [c(t) + d(t)X] \\, dB\\] where \\(a, b, c, d\\) are deterministic functions, can always be solved using integrating factors. The solution involves: 1. Solving the homogeneous equation 2. Variation of parameters for the particular solution 3. Combining with the stochastic integral This parallels the theory of linear ODEs, but with stochastic integrals replacing ordinary integrals. 3.6 Existence and Uniqueness When does an SDE have a solution? When is it unique? Theorem (Existence and Uniqueness): If \\(\\mu(t, x)\\) and \\(\\sigma(t, x)\\) satisfy: Lipschitz condition: There exists \\(K &gt; 0\\) such that \\[|\\mu(t,x) - \\mu(t,y)| + |\\sigma(t,x) - \\sigma(t,y)| \\leq K|x - y|\\] for all \\(t, x, y\\) Linear growth: There exists \\(C &gt; 0\\) such that \\[|\\mu(t,x)| + |\\sigma(t,x)| \\leq C(1 + |x|)\\] for all \\(t, x\\) Then the SDE has a unique strong solution for any initial condition \\(X(0)\\). These conditions ensure the drift and diffusion are “nice enough” - not too wild or growing too fast. 3.7 Strong vs. Weak Solutions Strong solution: Constructed pathwise on a given probability space with a given Brownian motion Weak solution: The probability distribution of the solution is specified, but the construction may vary Most applications in finance use weak solutions - we care about distributions of prices, not individual paths. 3.8 Multidimensional SDEs SDEs can be vectors: \\[dX_i = \\mu_i(t, \\mathbf{X}) \\, dt + \\sum_{j=1}^d \\sigma_{ij}(t, \\mathbf{X}) \\, dB_j\\] where \\(\\mathbf{X} = (X_1, \\ldots, X_n)\\) and \\(B_1, \\ldots, B_d\\) are independent Brownian motions. The matrix \\(\\sigma = (\\sigma_{ij})\\) is the diffusion matrix. The covariance structure is: \\[d\\langle X_i, X_j \\rangle = \\sum_{k=1}^d \\sigma_{ik} \\sigma_{jk} \\, dt = (\\sigma \\sigma^T)_{ij} \\, dt\\] Multidimensional Itô’s lemma becomes: \\[df(\\mathbf{X}) = \\sum_i \\frac{\\partial f}{\\partial x_i} dX_i + \\frac{1}{2}\\sum_{i,j} \\frac{\\partial^2 f}{\\partial x_i \\partial x_j} d\\langle X_i, X_j \\rangle\\] This is essential for modeling portfolios, interest rate curves, and other multivariate phenomena. "],["feynman-kac-and-pdes.html", "Chapter 4 Feynman-Kac and PDEs 4.1 The Bridge Between Probability and Analysis 4.2 The Backward Kolmogorov Equation 4.3 Example: The Heat Equation 4.4 The Black-Scholes PDE 4.5 The Forward Kolmogorov Equation 4.6 Feynman-Kac Formula (General Version) 4.7 Applications 4.8 Numerical Methods 4.9 Summary", " Chapter 4 Feynman-Kac and PDEs 4.1 The Bridge Between Probability and Analysis One of the most beautiful results in mathematics connects two seemingly different worlds: Stochastic differential equations (SDEs) - the probabilistic world Partial differential equations (PDEs) - the analytical world This connection, known as the Feynman-Kac formula, allows us to: - Solve PDEs by simulating random processes (Monte Carlo) - Solve SDEs by solving PDEs (numerical PDE methods) - Gain intuition about both simultaneously 4.2 The Backward Kolmogorov Equation Consider an SDE: \\[dX(t) = \\mu(X) \\, dt + \\sigma(X) \\, dB(t)\\] Define the function: \\[u(t, x) = E[g(X(T)) \\mid X(t) = x]\\] This represents the expected value of some payoff function \\(g\\) at terminal time \\(T\\), given that the process is at position \\(x\\) at time \\(t\\). Question: What PDE does \\(u(t,x)\\) satisfy? 4.2.1 Heuristic Derivation Apply Itô’s lemma to \\(u(t, X(t))\\): \\[du = \\frac{\\partial u}{\\partial t}dt + \\frac{\\partial u}{\\partial x}dX + \\frac{1}{2}\\frac{\\partial^2 u}{\\partial x^2}(dX)^2\\] Substitute \\(dX = \\mu \\, dt + \\sigma \\, dB\\) and \\((dX)^2 = \\sigma^2 \\, dt\\): \\[du = \\left[\\frac{\\partial u}{\\partial t} + \\mu\\frac{\\partial u}{\\partial x} + \\frac{1}{2}\\sigma^2\\frac{\\partial^2 u}{\\partial x^2}\\right]dt + \\sigma\\frac{\\partial u}{\\partial x}dB\\] Integrate from \\(t\\) to \\(T\\) and take expectations. The stochastic integral has zero expectation, so: \\[E[u(T, X(T))] - u(t, x) = E\\left[\\int_t^T \\left(\\frac{\\partial u}{\\partial s} + \\mu\\frac{\\partial u}{\\partial x} + \\frac{1}{2}\\sigma^2\\frac{\\partial^2 u}{\\partial x^2}\\right)ds\\right]\\] At terminal time: \\(u(T, X(T)) = g(X(T))\\) by definition. For this to hold for all paths, we need: \\[\\boxed{\\frac{\\partial u}{\\partial t} + \\mu(x)\\frac{\\partial u}{\\partial x} + \\frac{1}{2}\\sigma^2(x)\\frac{\\partial^2 u}{\\partial x^2} = 0}\\] with boundary condition \\(u(T, x) = g(x)\\). This is the backward Kolmogorov equation (also called the Fokker-Planck backward equation). 4.3 Example: The Heat Equation Take the simplest SDE: \\(dX = dB\\) (pure Brownian motion, \\(\\mu = 0\\), \\(\\sigma = 1\\)). The backward equation becomes: \\[\\frac{\\partial u}{\\partial t} + \\frac{1}{2}\\frac{\\partial^2 u}{\\partial x^2} = 0\\] Change time direction by setting \\(\\tau = T - t\\): \\[\\boxed{\\frac{\\partial u}{\\partial \\tau} = \\frac{1}{2}\\frac{\\partial^2 u}{\\partial x^2}}\\] This is the heat equation! 4.3.1 Probabilistic Interpretation The solution to the heat equation with initial condition \\(u(0, x) = g(x)\\) is: \\[u(\\tau, x) = E[g(X(\\tau)) \\mid X(0) = x] = \\int_{-\\infty}^{\\infty} g(y) \\frac{1}{\\sqrt{2\\pi\\tau}} e^{-(y-x)^2/(2\\tau)} dy\\] The heat kernel \\(\\frac{1}{\\sqrt{2\\pi\\tau}} e^{-(y-x)^2/(2\\tau)}\\) is precisely the transition density of Brownian motion! Deep insight: Heat diffusion is mathematically identical to Brownian motion. Temperature spreads like a random walk. 4.4 The Black-Scholes PDE Now consider geometric Brownian motion: \\[dS = \\mu S \\, dt + \\sigma S \\, dB\\] For a derivative with payoff \\(g(S(T))\\) at time \\(T\\), we want the price: \\[V(t, S) = E[g(S(T)) \\mid S(t) = S]\\] But we need to account for discounting at the risk-free rate \\(r\\). In a risk-neutral world (more on this later), we replace \\(\\mu\\) with \\(r\\) and define: \\[V(t, S) = e^{-r(T-t)}E^{\\mathbb{Q}}[g(S(T)) \\mid S(t) = S]\\] Let \\(u(t, S) = e^{-r(T-t)}V(t, S)\\) to factor out the discounting. By Itô’s lemma and similar arguments: \\[\\boxed{\\frac{\\partial V}{\\partial t} + rS\\frac{\\partial V}{\\partial S} + \\frac{1}{2}\\sigma^2 S^2\\frac{\\partial^2 V}{\\partial S^2} = rV}\\] with terminal condition \\(V(T, S) = g(S)\\). This is the Black-Scholes PDE! 4.4.1 Solving for a European Call For \\(g(S) = \\max(S - K, 0)\\), the solution is: \\[V(t, S) = S\\Phi(d_1) - Ke^{-r(T-t)}\\Phi(d_2)\\] where: \\[d_1 = \\frac{\\log(S/K) + (r + \\sigma^2/2)(T-t)}{\\sigma\\sqrt{T-t}}, \\quad d_2 = d_1 - \\sigma\\sqrt{T-t}\\] We’ll derive this in the next chapter using risk-neutral pricing. 4.5 The Forward Kolmogorov Equation There’s also a forward equation that describes how the probability density \\(p(t, x)\\) of \\(X(t)\\) evolves: \\[\\frac{\\partial p}{\\partial t} = -\\frac{\\partial}{\\partial x}[\\mu(x)p] + \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}[\\sigma^2(x)p]\\] This is the forward Kolmogorov equation (or Fokker-Planck forward equation). 4.5.1 The Duality Backward equation: Expects values along future paths (pricing) Forward equation: Probability density evolution (statistical mechanics) These are dual perspectives on the same stochastic process. 4.6 Feynman-Kac Formula (General Version) The most general form handles running costs and discounting: Theorem: Consider the SDE \\(dX = \\mu(X) \\, dt + \\sigma(X) \\, dB\\) with initial condition \\(X(t) = x\\). Define: \\[u(t, x) = E\\left[g(X(T))e^{-\\int_t^T c(X(s))ds} + \\int_t^T f(X(s))e^{-\\int_t^s c(X(r))dr}ds \\mid X(t) = x\\right]\\] Then \\(u\\) satisfies: \\[\\frac{\\partial u}{\\partial t} + \\mu\\frac{\\partial u}{\\partial x} + \\frac{1}{2}\\sigma^2\\frac{\\partial^2 u}{\\partial x^2} - c(x)u + f(x) = 0\\] with \\(u(T, x) = g(x)\\). Here: - \\(c(x)\\) is a discount rate (e.g., interest rate) - \\(f(x)\\) is a running payoff (e.g., dividends) - \\(g(x)\\) is terminal payoff 4.7 Applications 4.7.1 Option Pricing The Feynman-Kac formula underpins all of option pricing theory: - Price = expected discounted payoff under risk-neutral measure - Can solve either the PDE or simulate the SDE 4.7.2 Statistical Mechanics In physics, the heat equation describes: - Temperature diffusion - Particle density evolution - Quantum mechanics (Schrödinger equation with imaginary time) 4.7.3 Control Theory Optimal control problems (Hamilton-Jacobi-Bellman equations) connect to SDEs through Feynman-Kac. 4.7.4 Biology Population dynamics, gene frequency evolution, and neural activity models all use this connection. 4.8 Numerical Methods 4.8.1 Monte Carlo Simulation To compute \\(u(t,x) = E[g(X(T)) \\mid X(t) = x]\\): Simulate many paths of the SDE starting from \\(X(t) = x\\) Evaluate \\(g(X(T))\\) for each path Average the results Advantages: Easy to implement, works in high dimensions Disadvantages: Slow convergence (\\(\\mathcal{O}(1/\\sqrt{N})\\)), difficult for early exercise 4.8.2 PDE Methods Discretize the PDE on a grid using: - Finite differences (explicit, implicit, Crank-Nicolson) - Finite elements - Spectral methods Advantages: Fast, handles early exercise naturally Disadvantages: Curse of dimensionality, boundary conditions tricky 4.8.3 Hybrid Methods Modern approaches combine both: - Use PDE methods when low-dimensional - Use Monte Carlo when high-dimensional - Use sparse grids, reduced basis methods, etc. 4.9 Summary The Feynman-Kac connection is profound: SDE: dX = μdt + σdB ↓ (Itô&#39;s lemma) PDE: ∂u/∂t + μ∂u/∂x + ½σ²∂²u/∂x² = 0 ↕ (Feynman-Kac) Probabilistic representation: u(t,x) = E[g(X(T)) | X(t)=x] This bridges: - Probability ↔︎ Analysis - Random walks ↔︎ Differential equations - Simulation ↔︎ Analytic solutions - Physics ↔︎ Finance It’s one of the most beautiful and useful results in applied mathematics. "],["risk-neutral-pricing-and-martingales.html", "Chapter 5 Risk-Neutral Pricing and Martingales 5.1 Martingales: Fair Games 5.2 The Fundamental Theorem of Asset Pricing 5.3 Risk-Neutral Pricing Formula 5.4 Why Does This Work? 5.5 Example: Forward Contracts 5.6 Change of Numeraire 5.7 Market Price of Risk 5.8 Incomplete Markets 5.9 Summary", " Chapter 5 Risk-Neutral Pricing and Martingales 5.1 Martingales: Fair Games A stochastic process \\(M(t)\\) is a martingale if: \\[E[M(t) \\mid \\mathcal{F}_s] = M(s) \\quad \\text{for all } t \\geq s\\] where \\(\\mathcal{F}_s\\) represents all information up to time \\(s\\). Intuitive meaning: The best prediction of tomorrow’s value is today’s value. No drift, just random fluctuations. It’s a “fair game” - you can’t make money on average. Key property: If \\(M(t)\\) is a martingale, then \\(E[M(t)] = E[M(0)]\\) for all \\(t\\). 5.1.1 Examples Brownian motion: \\(B(t)\\) is a martingale Itô integral: \\(\\int_0^t f(s) \\, dB(s)\\) is a martingale (if \\(f\\) satisfies certain conditions) Exponential martingale: \\(\\exp(\\sigma B(t) - \\frac{1}{2}\\sigma^2 t)\\) is a martingale Casino winnings: Your wealth in a fair game 5.2 The Fundamental Theorem of Asset Pricing This is the nuclear bomb of mathematical finance: Theorem: A market is arbitrage-free if and only if there exists a probability measure \\(\\mathbb{Q}\\) (the risk-neutral measure) under which all discounted asset prices are martingales. Let me unpack this carefully. 5.2.1 What’s Arbitrage? An arbitrage is a “free lunch” - a trading strategy that: 1. Costs nothing to set up 2. Never loses money 3. Sometimes makes money Markets without arbitrage are called arbitrage-free. This is a minimal rationality assumption. 5.2.2 The Risk-Neutral Measure In the real world (measure \\(\\mathbb{P}\\)), a stock might follow: \\[dS = \\mu S \\, dt + \\sigma S \\, dB\\] where \\(\\mu\\) is the real drift (could be 8%, 12%, whatever). The discounted price is \\(\\tilde{S}(t) = e^{-rt}S(t)\\) where \\(r\\) is the risk-free rate. By Itô’s lemma: \\[d\\tilde{S} = \\tilde{S}[(\\mu - r)dt + \\sigma \\, dB]\\] This has drift \\(\\mu - r\\). If \\(\\mu \\neq r\\), this is NOT a martingale under \\(\\mathbb{P}\\). The trick: Change to a different probability measure \\(\\mathbb{Q}\\) where the drift vanishes! 5.2.3 Girsanov’s Theorem Under \\(\\mathbb{Q}\\), we define a new Brownian motion: \\[\\tilde{B}(t) = B(t) + \\frac{\\mu - r}{\\sigma}t\\] By Girsanov’s theorem (deep measure theory), \\(\\tilde{B}(t)\\) is a Brownian motion under \\(\\mathbb{Q}\\). Then under \\(\\mathbb{Q}\\): \\[d\\tilde{S} = \\tilde{S}\\sigma \\, d\\tilde{B}\\] No drift! The discounted stock price is a martingale under \\(\\mathbb{Q}\\). 5.3 Risk-Neutral Pricing Formula Since \\(\\tilde{S}(t) = e^{-rt}S(t)\\) is a \\(\\mathbb{Q}\\)-martingale: \\[e^{-rt}S(t) = E^{\\mathbb{Q}}[e^{-rT}S(T) \\mid \\mathcal{F}_t]\\] For a derivative with payoff \\(g(S(T))\\) at time \\(T\\), no-arbitrage requires: \\[\\boxed{V(t) = e^{-r(T-t)}E^{\\mathbb{Q}}[g(S(T)) \\mid S(t)]}\\] This is the universal pricing formula! 5.3.1 The Miracle The real drift \\(\\mu\\) doesn’t appear! Risk preferences are already encoded in \\(S(t)\\) Only need: \\(S(t)\\), \\(r\\), \\(\\sigma\\), and payoff \\(g\\) Under \\(\\mathbb{Q}\\), assets grow at rate \\(r\\) (not \\(\\mu\\)): \\[dS = rS \\, dt + \\sigma S \\, d\\tilde{B}\\] This is why it’s called “risk-neutral” - it’s as if investors are indifferent to risk. 5.4 Why Does This Work? The key insight: replication. If you can replicate the derivative’s payoff using the underlying asset, then to avoid arbitrage, the derivative’s price must equal the replication cost. The risk-neutral measure emerges from imposing no-arbitrage across all possible replication strategies. 5.5 Example: Forward Contracts A forward contract obliges you to buy stock at price \\(K\\) at time \\(T\\). Payoff: \\(S(T) - K\\). Price: \\[V(t) = e^{-r(T-t)}E^{\\mathbb{Q}}[S(T) - K]\\] \\[= e^{-r(T-t)}[E^{\\mathbb{Q}}[S(T)] - K]\\] \\[= e^{-r(T-t)}[S(t)e^{r(T-t)} - K]\\] \\[= S(t) - Ke^{-r(T-t)}\\] The forward price (fair delivery price) is \\(F = S(t)e^{r(T-t)}\\). 5.6 Change of Numeraire You can use any traded asset as the “numeraire” (unit of account). If you use asset \\(N(t)\\) as numeraire, there exists a measure \\(\\mathbb{Q}^N\\) under which all prices relative to \\(N(t)\\) are martingales: \\[\\frac{S(t)}{N(t)} \\text{ is a } \\mathbb{Q}^N\\text{-martingale}\\] Common choices: - Money market account: \\(N(t) = e^{rt}\\) → standard risk-neutral measure - Zero-coupon bond: Useful for interest rate derivatives - Stock itself: Useful for options on options This technique is powerful for simplifying derivative pricing. 5.7 Market Price of Risk The drift shift from \\(\\mathbb{P}\\) to \\(\\mathbb{Q}\\) is governed by the market price of risk \\(\\lambda\\): \\[\\lambda = \\frac{\\mu - r}{\\sigma}\\] This measures the excess return per unit of volatility. Under \\(\\mathbb{Q}\\): \\[d\\tilde{B} = dB + \\lambda \\, dt\\] Different assets may have different market prices of risk. In a complete market, all risks are spanned by traded assets, so there’s a unique \\(\\mathbb{Q}\\). 5.8 Incomplete Markets If not all risks can be hedged (e.g., jumps, stochastic volatility without tradable volatility derivatives), the market is incomplete. Then: - Multiple risk-neutral measures exist - No unique price for derivatives - Need to choose \\(\\mathbb{Q}\\) based on additional criteria (e.g., minimize risk, match market prices) This is a major research area in quantitative finance. 5.9 Summary The martingale approach to pricing: Identify the source of randomness (Brownian motions) Find the risk-neutral measure (Girsanov theorem) Price as discounted expectation under \\(\\mathbb{Q}\\) This elegant framework unifies all of derivative pricing and connects probability theory to finance in a profound way. "],["black-scholes-theory.html", "Chapter 6 Black-Scholes Theory 6.1 The Black-Scholes Formula 6.2 The Greeks 6.3 Delta Hedging 6.4 Put-Call Parity 6.5 Implied Volatility 6.6 American Options 6.7 Extensions 6.8 Limitations of Black-Scholes", " Chapter 6 Black-Scholes Theory 6.1 The Black-Scholes Formula For a European call option with strike \\(K\\) and maturity \\(T\\), the price at time \\(t\\) with stock price \\(S\\) is: \\[\\boxed{C(t, S) = S\\Phi(d_1) - Ke^{-r(T-t)}\\Phi(d_2)}\\] where: \\[d_1 = \\frac{\\log(S/K) + (r + \\sigma^2/2)(T-t)}{\\sigma\\sqrt{T-t}}, \\quad d_2 = d_1 - \\sigma\\sqrt{T-t}\\] and \\(\\Phi\\) is the standard normal CDF. 6.1.1 Derivation Under the risk-neutral measure, stock price evolves as: \\[S(T) = S(t)\\exp\\left[\\left(r - \\frac{\\sigma^2}{2}\\right)(T-t) + \\sigma\\sqrt{T-t}Z\\right]\\] where \\(Z \\sim N(0,1)\\). The call price is: \\[C = e^{-r(T-t)}E^{\\mathbb{Q}}[\\max(S(T) - K, 0)]\\] After working through the integral (completing the square), we obtain the formula above. 6.1.2 Interpretation \\[C = S\\Phi(d_1) - Ke^{-r(T-t)}\\Phi(d_2)\\] \\(S\\Phi(d_1)\\): Expected present value of stock if exercised \\(Ke^{-r(T-t)}\\Phi(d_2)\\): Expected present value of strike payment \\(\\Phi(d_2)\\): Risk-neutral probability option finishes in-the-money \\(\\Phi(d_1)\\): “Delta” of the option (hedge ratio) 6.2 The Greeks The Greeks measure sensitivities of option prices to various parameters. They’re essential for risk management and hedging. 6.2.1 Delta (\\(\\Delta\\)) \\[\\Delta = \\frac{\\partial C}{\\partial S} = \\Phi(d_1)\\] Interpretation: - How much the option price changes per $1 change in stock price - Hedge ratio: to hedge a short call, buy \\(\\Delta\\) shares - Ranges from 0 (deep out-of-money) to 1 (deep in-the-money) 6.2.2 Gamma (\\(\\Gamma\\)) \\[\\Gamma = \\frac{\\partial^2 C}{\\partial S^2} = \\frac{\\phi(d_1)}{S\\sigma\\sqrt{T-t}}\\] where \\(\\phi\\) is the standard normal PDF. Interpretation: - Rate of change of Delta - Measures convexity of option price - Maximum at-the-money - Hedging \\(\\Gamma\\) is expensive (requires frequent rebalancing) 6.2.3 Vega (\\(\\mathcal{V}\\)) \\[\\mathcal{V} = \\frac{\\partial C}{\\partial \\sigma} = S\\phi(d_1)\\sqrt{T-t}\\] Interpretation: - Sensitivity to volatility - Options are “long volatility” - gain value when \\(\\sigma\\) increases - Maximum at-the-money - Long-dated options have more Vega 6.2.4 Theta (\\(\\Theta\\)) \\[\\Theta = \\frac{\\partial C}{\\partial t} = -\\frac{S\\phi(d_1)\\sigma}{2\\sqrt{T-t}} - rKe^{-r(T-t)}\\Phi(d_2)\\] Interpretation: - Time decay - value lost per day - Usually negative for long options (you lose time value) - Accelerates as expiration approaches 6.2.5 Rho (\\(\\rho\\)) \\[\\rho = \\frac{\\partial C}{\\partial r} = K(T-t)e^{-r(T-t)}\\Phi(d_2)\\] Interpretation: - Sensitivity to interest rates - Usually less important than other Greeks - More relevant for long-dated options 6.2.6 The Greeks Relationship They satisfy the Black-Scholes PDE: \\[\\Theta + \\frac{1}{2}\\sigma^2 S^2\\Gamma + rS\\Delta - rC = 0\\] This connects time decay, convexity, and delta in a beautiful way. 6.3 Delta Hedging You’re a market maker who sold a call option. How to hedge the risk? 6.3.1 The Strategy At time \\(t\\): Hold \\(\\Delta(t) = \\Phi(d_1)\\) shares of stock As stock moves: Continuously rebalance to maintain \\(\\Delta(t)\\) shares If hedged perfectly with correct volatility: Earn the risk-free rate 6.3.2 Discrete Hedging P&amp;L Over small time \\(dt\\), the P&amp;L is approximately: \\[dP\\&amp;L \\approx \\frac{1}{2}\\Gamma(dS)^2 - \\Theta \\, dt\\] \\((dS)^2\\) term: Realized variance \\(\\Theta\\) term: Time decay If realized volatility = implied volatility used for pricing, these balance out. 6.3.3 The Catch In practice: - Can’t rebalance continuously (transaction costs) - Don’t know true volatility in advance - If realized vol \\(\\neq\\) implied vol, you make/lose money This is why options trading is essentially trading volatility! 6.4 Put-Call Parity For European options with same strike and maturity: \\[C - P = S - Ke^{-r(T-t)}\\] Proof: Both sides have payoff \\(S(T) - K\\) at maturity. By no-arbitrage, they must have equal value today. Uses: - Price puts from calls (or vice versa) - Identify arbitrage opportunities - Understand synthetic positions 6.5 Implied Volatility The market quotes option prices, not volatilities. Implied volatility is the \\(\\sigma\\) that makes the Black-Scholes formula match the market price: \\[C_{\\text{market}} = C_{BS}(S, K, T, r, \\sigma_{implied})\\] 6.5.1 The Volatility Smile In practice, implied volatility varies with strike: - Equity markets: Volatility skew (higher for low strikes) - FX markets: Volatility smile (higher for extreme strikes) This violates Black-Scholes assumptions! Real markets have: - Fat tails (more crashes than log-normal predicts) - Stochastic volatility - Jumps Modern models address these issues. 6.6 American Options American options can be exercised anytime before maturity. No closed-form formula exists! Must solve the free boundary problem: \\[\\max\\left(\\frac{\\partial V}{\\partial t} + \\frac{1}{2}\\sigma^2 S^2\\frac{\\partial^2 V}{\\partial S^2} + rS\\frac{\\partial V}{\\partial S} - rV, \\, g(S) - V\\right) = 0\\] where \\(g(S)\\) is the exercise payoff. 6.6.1 Early Exercise Premium \\[V_{American} = V_{European} + \\text{Early Exercise Premium}\\] For calls on non-dividend paying stocks: Early exercise premium = 0 (never optimal to exercise early). For puts: Early exercise can be optimal (when deep in-the-money). 6.7 Extensions 6.7.1 Dividends If stock pays continuous dividend yield \\(q\\): \\[C = Se^{-q(T-t)}\\Phi(d_1) - Ke^{-r(T-t)}\\Phi(d_2)\\] where \\(d_1, d_2\\) are modified to include \\(q\\). 6.7.2 Exotic Options Digital options: Pay $1 or $0 Barrier options: Activated/deactivated if stock crosses barrier Asian options: Payoff depends on average price Lookback options: Payoff depends on maximum/minimum Each requires specialized techniques! 6.8 Limitations of Black-Scholes Constant volatility: Real volatility varies and is stochastic No jumps: Stocks can gap (earnings, news) Log-normal distribution: Real returns have fat tails Continuous trading: Transaction costs exist Known parameters: Volatility and drift are unknown Despite limitations, Black-Scholes is: - A benchmark for pricing and hedging - The foundation for more sophisticated models - Still widely used (with adjustments) The framework is more important than the formula itself! "],["jump-diffusion-models.html", "Chapter 7 Jump-Diffusion Models 7.1 Why Jumps Matter 7.2 The Poisson Process 7.3 Compound Poisson Process 7.4 Merton’s Jump-Diffusion Model 7.5 Itô’s Lemma with Jumps 7.6 Risk-Neutral Pricing with Jumps 7.7 Merton’s Option Pricing Formula 7.8 The PIDE 7.9 Market Implications 7.10 Extensions 7.11 Summary", " Chapter 7 Jump-Diffusion Models 7.1 Why Jumps Matter Brownian motion assumes continuous price paths. But real markets exhibit: Earnings announcements: Stock gaps 10%+ overnight Central bank decisions: FX rates jump instantly Black swan events: Market crashes, flash crashes Fat tails: Extreme returns occur more often than log-normal predicts Purely diffusive models systematically underprice out-of-the-money options. 7.2 The Poisson Process Before jumps, we need to count random events. Definition: \\(N(t)\\) is a Poisson process with intensity \\(\\lambda\\) if: \\(N(0) = 0\\) Independent increments \\(N(t) - N(s) \\sim \\text{Poisson}(\\lambda(t-s))\\) for \\(t &gt; s\\) Paths are step functions (jumps of size 1) Properties: - \\(E[N(t)] = \\lambda t\\) (average \\(\\lambda\\) events per unit time) - \\(\\text{Var}(N(t)) = \\lambda t\\) - \\(P(N(t) = k) = \\frac{(\\lambda t)^k e^{-\\lambda t}}{k!}\\) - Waiting times between events: exponential with rate \\(\\lambda\\) Differential notation: \\[dN(t) = \\begin{cases} 1 &amp; \\text{with probability } \\lambda \\, dt \\\\ 0 &amp; \\text{with probability } 1 - \\lambda \\, dt \\end{cases}\\] Key property: \\((dN)^2 = dN\\) (since \\(dN \\in \\{0,1\\}\\) and \\(1^2 = 1\\)). 7.3 Compound Poisson Process Add random jump sizes: \\[J(t) = \\sum_{i=1}^{N(t)} Y_i\\] where \\(Y_i\\) are i.i.d. random jumps (often \\(Y_i \\sim N(\\mu_J, \\sigma_J^2)\\)). In differential form: \\[dJ(t) = Y \\, dN(t)\\] where \\(Y\\) is drawn when a jump occurs. 7.4 Merton’s Jump-Diffusion Model Combine Brownian motion with compound Poisson jumps: \\[\\boxed{\\frac{dS}{S} = \\mu \\, dt + \\sigma \\, dB + (e^Y - 1) \\, dN}\\] Components: - \\(\\mu \\, dt\\): Deterministic drift - \\(\\sigma \\, dB\\): Continuous diffusion (Brownian) - \\((e^Y - 1) \\, dN\\): Discontinuous jumps Jump structure: - Jumps arrive with intensity \\(\\lambda\\) - When jump occurs: \\(S \\to S \\cdot e^Y\\) (multiplicative) - Typically \\(Y \\sim N(\\mu_J, \\sigma_J^2)\\) (log-normal jumps) 7.4.1 Why \\(e^Y - 1\\)? If \\(Y = \\log(1 + k)\\) where \\(k\\) is the percentage jump: \\[S_{\\text{after}} = S_{\\text{before}} \\cdot e^Y = S_{\\text{before}} \\cdot (1 + k)\\] So a 10% down move corresponds to \\(Y = \\log(0.9) \\approx -0.105\\). 7.5 Itô’s Lemma with Jumps For a function \\(f(S)\\) where \\(S\\) follows jump-diffusion, Itô’s lemma becomes: \\[df = \\frac{\\partial f}{\\partial S}dS + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial S^2}(dS)^2 + [f(Se^Y) - f(S) - \\frac{\\partial f}{\\partial S}S(e^Y - 1)]\\,dN\\] The last term is the jump correction: actual jump minus first-order Taylor approximation. Multiplication rules: - \\(dB \\cdot dN = 0\\) (jumps and diffusion independent) - \\(dt \\cdot dN = 0\\) - \\(dN \\cdot dN = dN\\) (only one jump at a time) 7.5.1 Example: Log Price Apply to \\(f(S) = \\log S\\): \\[d(\\log S) = \\left(\\mu - \\frac{\\sigma^2}{2}\\right)dt + \\sigma \\, dB + Y \\, dN\\] Integrating: \\[\\log S(t) = \\log S(0) + \\left(\\mu - \\frac{\\sigma^2}{2}\\right)t + \\sigma B(t) + \\sum_{i=1}^{N(t)} Y_i\\] Log price = drift + Brownian + sum of jumps. Clean decomposition! 7.6 Risk-Neutral Pricing with Jumps Under \\(\\mathbb{Q}\\), discounted price must be martingale: \\[\\frac{dS}{S} = (r - \\lambda \\kappa) \\, dt + \\sigma \\, d\\tilde{B} + (e^Y - 1) \\, d\\tilde{N}\\] where \\(\\kappa = E^{\\mathbb{Q}}[e^Y - 1]\\) is the expected jump size. The drift adjustment \\(-\\lambda \\kappa\\) compensates for jumps to maintain martingale property. If jumps are log-normal: \\(Y \\sim N(\\mu_J, \\sigma_J^2)\\), then: \\[\\kappa = e^{\\mu_J + \\sigma_J^2/2} - 1\\] 7.6.1 The Critical Insight With jumps, you cannot perfectly hedge! Jump risk cannot be eliminated through continuous rebalancing. This fundamentally changes the pricing problem. 7.7 Merton’s Option Pricing Formula For a European call: \\[\\boxed{C(S, t) = \\sum_{n=0}^{\\infty} \\frac{e^{-\\lambda&#39;(T-t)}[\\lambda&#39;(T-t)]^n}{n!} \\text{BS}(S, K, r_n, \\sigma_n, T-t)}\\] where: - \\(\\lambda&#39; = \\lambda(1 + \\kappa)\\) is adjusted intensity - \\(\\text{BS}(\\cdot)\\) is Black-Scholes formula with modified parameters: - \\(r_n = r - \\lambda\\kappa + \\frac{n\\log(1+\\kappa)}{T-t}\\) - \\(\\sigma_n^2 = \\sigma^2 + \\frac{n\\sigma_J^2}{T-t}\\) Interpretation: Weighted average of Black-Scholes prices, each term corresponding to exactly \\(n\\) jumps before maturity. 7.8 The PIDE For general derivatives, the pricing equation becomes a partial integro-differential equation: \\[\\frac{\\partial V}{\\partial t} + (r - \\lambda\\kappa)S\\frac{\\partial V}{\\partial S} + \\frac{1}{2}\\sigma^2 S^2\\frac{\\partial^2 V}{\\partial S^2}\\] \\[+ \\lambda\\int_{-\\infty}^{\\infty}[V(t, Se^y) - V(t,S)]f(y)\\,dy = rV\\] The integral accounts for all possible jump outcomes, weighted by their probability density \\(f(y)\\). Much harder to solve than Black-Scholes PDE! Typically requires numerical methods: - Monte Carlo simulation - Fourier methods (FFT) - Finite difference on jump-diffusion grid 7.9 Market Implications 7.9.1 Volatility Smile Jump models naturally produce volatility smiles: - Out-of-the-money puts protect against downward jumps → higher implied vol - Near-the-money options less affected → lower implied vol - Creates the characteristic “smirk” in equity markets 7.9.2 Greeks Greeks behave differently with jumps: - Delta no longer perfect hedge ratio - Vega has two components: diffusion vol + jump vol - New Greeks: sensitivity to jump intensity (\\(\\partial V/\\partial \\lambda\\)), jump size - Jump risk premium: additional risk that can’t be hedged 7.9.3 Calibration More parameters to fit: - Brownian: \\(\\mu\\), \\(\\sigma\\) - Jumps: \\(\\lambda\\), \\(\\mu_J\\), \\(\\sigma_J\\) Pros: More flexible, fits market data better Cons: Harder to calibrate, identifiability issues 7.10 Extensions 7.10.1 Double exponential jumps Use asymmetric exponential distributions for up/down jumps: \\[f(y) = \\begin{cases} p \\eta_u e^{-\\eta_u y} &amp; y \\geq 0 \\\\ (1-p) \\eta_d e^{\\eta_d y} &amp; y &lt; 0 \\end{cases}\\] Allows different behavior for positive and negative jumps (market asymmetry). 7.10.2 Stochastic intensity Let \\(\\lambda\\) itself be random: \\[d\\lambda = a(\\lambda) \\, dt + b(\\lambda) \\, dW\\] Models “volatility clustering” of jumps (crises come in waves). 7.10.3 Jump-to-default Special case: when jump occurs, stock goes to zero (bankruptcy): \\[P(\\text{jump to default in } dt) = h \\, dt\\] Used in credit risk models. 7.11 Summary Jump-diffusion models capture: - Discrete shocks in addition to continuous uncertainty - Fat tails and skewness in return distributions - Incomplete markets and non-hedgeable risk - More realistic market dynamics They’re the bridge between Black-Scholes and more sophisticated Lévy process models. "],["lévy-processes.html", "Chapter 8 Lévy Processes 8.1 The Ultimate Generalization 8.2 Examples We Know 8.3 The Lévy-Khintchine Representation 8.4 Types of Jump Behavior 8.5 Popular Lévy Processes in Finance 8.6 Why Lévy Processes Matter for Finance 8.7 Pricing with Lévy Processes 8.8 The Lévy Landscape 8.9 Subordination 8.10 Limitations and Extensions 8.11 The Full Circle 8.12 Further Directions", " Chapter 8 Lévy Processes 8.1 The Ultimate Generalization Lévy processes unify everything we’ve learned: random walks, Brownian motion, Poisson processes, and jump-diffusions are all special cases. Definition: A process \\(L(t)\\) is a Lévy process if: \\(L(0) = 0\\) Independent increments: \\(L(t) - L(s)\\) independent of past for \\(t &gt; s\\) Stationary increments: \\(L(t) - L(s) \\sim L(t-s)\\) (distribution depends only on time difference) Stochastic continuity: \\(\\lim_{h \\to 0} P(|L(t+h) - L(t)| &gt; \\epsilon) = 0\\) for all \\(\\epsilon &gt; 0\\) Càdlàg paths: Right-continuous with left limits (allows jumps) Lévy processes are the natural class of “time-homogeneous processes with independent increments.” 8.2 Examples We Know All of these are Lévy processes: Brownian motion: Continuous paths, no jumps Poisson process: Jumps of size 1 Compound Poisson: Random-sized jumps at Poisson times Merton jump-diffusion: Brownian + Compound Poisson Stable processes: Including Cauchy process Variance Gamma: Time-changed Brownian motion Normal Inverse Gaussian (NIG): Popular in finance 8.3 The Lévy-Khintchine Representation Here’s the magic: Every Lévy process decomposes into three independent parts: \\[\\boxed{L(t) = \\gamma t + \\sigma B(t) + J(t)}\\] where: \\(\\gamma t\\): Linear drift (deterministic) \\(\\sigma B(t)\\): Brownian component (continuous random) \\(J(t)\\): Pure jump component (discontinuous) The jump component is characterized by a Lévy measure \\(\\nu(dy)\\) which tells us: - How often jumps of size around \\(y\\) occur - Can have infinitely many jumps in finite time! 8.3.1 The Lévy-Khintchine Formula The characteristic function (Fourier transform) is: \\[E[e^{i\\theta L(t)}] = \\exp\\left[t\\psi(\\theta)\\right]\\] where the Lévy symbol is: \\[\\psi(\\theta) = i\\theta\\gamma - \\frac{1}{2}\\sigma^2\\theta^2 + \\int_{-\\infty}^{\\infty}(e^{i\\theta y} - 1 - i\\theta y\\mathbb{1}_{|y|&lt;1})\\nu(dy)\\] The Lévy triplet \\((\\gamma, \\sigma^2, \\nu)\\) completely characterizes any Lévy process! 8.4 Types of Jump Behavior The Lévy measure \\(\\nu\\) determines the jump structure. 8.4.1 Finite Activity \\[\\int \\nu(dy) &lt; \\infty\\] Finitely many jumps in any finite interval. Example: Compound Poisson. 8.4.2 Infinite Activity \\[\\int \\nu(dy) = \\infty\\] Infinitely many jumps, but most are tiny. Examples: Variance Gamma, NIG. Intuition: Like continuous process, but with “microstructure” of tiny jumps. 8.4.3 Finite Variation \\[\\int |y| \\nu(dy) &lt; \\infty\\] Total jump variation is finite. Path has bounded variation. 8.4.4 Infinite Variation \\[\\int |y| \\nu(dy) = \\infty\\] Accumulation of many small jumps creates unbounded variation, like Brownian motion. 8.5 Popular Lévy Processes in Finance 8.5.1 Variance Gamma (VG) Infinite activity, finite variation Time-changed Brownian motion: \\(VG(t) = B(\\Gamma(t))\\) where \\(\\Gamma\\) is a gamma process Lévy density: \\(\\nu(dy) = \\frac{C}{|y|}e^{-\\lambda|y|}dy\\) Three parameters to fit: shape volatility smile Computationally tractable (FFT methods) Use: Equity options, capturing skewness and kurtosis. 8.5.2 Normal Inverse Gaussian (NIG) Infinite activity, infinite variation Hyperbolic distribution for log-returns Lévy density involves modified Bessel function Four parameters: very flexible Good fit to empirical return distributions Use: General modeling when need flexible, fat-tailed distribution. 8.5.3 CGMY (Carr-Geman-Madan-Yor) Generalizes many models Lévy density: \\(\\nu(dy) = C \\frac{e^{-G|y|}}{|y|^{1+Y}}\\) for \\(y &lt; 0\\), similar for \\(y &gt; 0\\) Parameter \\(Y\\) controls fine vs coarse structure: \\(Y &lt; 0\\): Finite activity \\(0 &lt; Y &lt; 1\\): Infinite activity, finite variation \\(1 &lt; Y &lt; 2\\): Infinite activity, infinite variation \\(Y = 0\\): Reduces to Variance Gamma Use: Ultimate flexibility in modeling jump behavior. 8.5.4 Tempered Stable Processes Compromise between stable (heavy tails) and exponential (light tails) Lévy density has power-law behavior near 0, exponential decay at infinity Captures both frequent small jumps and rare large jumps Use: Modeling extreme events while maintaining tractability. 8.6 Why Lévy Processes Matter for Finance 8.6.1 Empirical Fit Real asset return distributions exhibit: Fat tails: \\(P(|R| &gt; x)\\) decays slower than Gaussian Skewness: Asymmetric (negative skew for equities) Excess kurtosis: More peaked at center, fatter tails Lévy processes can match all three! 8.6.2 Infinite Divisibility Any time period can be subdivided arbitrarily: \\[L(t) \\stackrel{d}{=} L(t/n) + L(t/n) + \\cdots + L(t/n)\\] This mirrors the multiplicativity of returns in finance. 8.6.3 Tractability Despite complexity: Semi-closed form option prices via Fourier methods Fast computation using FFT Analytical Greeks (sometimes) Efficient simulation algorithms The balance of realism and tractability makes them practical. 8.7 Pricing with Lévy Processes For stock following: \\[\\frac{dS}{S} = r \\, dt + dL(t)\\] where \\(L\\) is a Lévy process under \\(\\mathbb{Q}\\), the option price satisfies: \\[\\frac{\\partial V}{\\partial t} + (r - \\psi(-i))S\\frac{\\partial V}{\\partial S} + \\frac{1}{2}\\sigma^2 S^2\\frac{\\partial^2 V}{\\partial S^2}\\] \\[+ \\int_{-\\infty}^{\\infty}\\left[V(t, Se^y) - V(t,S) - S(e^y - 1)\\frac{\\partial V}{\\partial S}\\right]\\nu(dy) = rV\\] This PIDE is generally solved using: Fourier methods: Transform to frequency domain, solve algebraically, transform back Monte Carlo: Simulate Lévy process paths, average payoffs Finite differences: Discretize the PIDE on a grid 8.7.1 Characteristic Function Method For European options, use: \\[C(K) = \\frac{e^{-rT}}{2\\pi}\\int_{-\\infty}^{\\infty} e^{-i\\omega \\log K} \\hat{g}(\\omega) \\, d\\omega\\] where \\(\\hat{g}\\) is the Fourier transform of the payoff function, computed using the characteristic function of \\(L(T)\\). Fast Fourier Transform (FFT) makes this efficient for computing prices across many strikes simultaneously. 8.8 The Lévy Landscape Lévy Processes | +----------------+----------------+ | | Continuous Jumps (Brownian) | +---------------+---------------+ | | Finite activity Infinite activity (Compound Poisson) | +---------------+---------------+ | | Finite variation Infinite variation (VG, some CGMY) (NIG, some CGMY) 8.9 Subordination Many Lévy processes arise through subordination: time-changing one process by another. If \\(X(t)\\) is a Lévy process and \\(T(t)\\) is an increasing Lévy process (subordinator), then: \\[Y(t) = X(T(t))\\] is also a Lévy process. Examples: - Variance Gamma: \\(VG(t) = B(T(t))\\) where \\(T\\) is gamma - NIG: Time-change Brownian motion by inverse Gaussian This gives an intuitive way to build flexible processes. 8.10 Limitations and Extensions 8.10.1 What Lévy processes cannot capture Stochastic volatility: Volatility itself random and path-dependent Volatility clustering: High volatility periods persist Long-range dependence: Correlations decay slowly 8.10.2 Modern extensions Lévy-driven SDEs: \\(dX = \\mu(X) dt + \\sigma(X) dL\\) Time-changed Lévy processes: Random time changes Lévy copulas: Multivariate Lévy dependence Fractional Lévy processes: Long memory Rough volatility: Paths rougher than Brownian These are active research areas combining stochastic calculus with other mathematical tools. 8.11 The Full Circle We started with: Random walks → (scaling) → Brownian motion → (SDEs) → Jump-diffusion → (generalization) → Lévy processes Each step added: - Brownian: Continuous randomness - SDEs: State-dependent dynamics - Jumps: Discontinuous shocks - Lévy: Full generality of time-homogeneous randomness All unified by: - PDEs/PIDEs (analytical methods) - Martingales (probabilistic methods) - Fourier methods (computational finance) - Itô calculus (the foundation) This framework underlies modern quantitative finance, connecting pure mathematics, probability theory, and real-world markets in a beautiful and practical way. 8.12 Further Directions Having mastered stochastic calculus and Lévy processes, you can explore: Stochastic volatility models (Heston, SABR) Local volatility and implied volatility surfaces Rough volatility and fractional Brownian motion Term structure models (interest rates, credit) Optimal stopping and American options Stochastic control and dynamic programming Filtering theory and partial information Malliavin calculus and Monte Carlo methods The journey never ends - but you now have the foundation to explore any of these advanced topics. Congratulations! "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
